---
layout: page
title: "Interactive Imitation Learning in State-Space"
subtitle: 
description:
permalink: /paper_147/
grand_parent: All Papers
parent: Tuesday
supp: 
code: https://github.com/sjauhri/Interactive-Learning-in-State-space
youtubeId: 
pdf: https://drive.google.com/file/d/1fRG-p4BaiGSoDw-Y0r6Fn80MXCV1TNW0/view
---

# Interactive Imitation Learning in State-Space

<a href="https://drive.google.com/file/d/1fRG-p4BaiGSoDw-Y0r6Fn80MXCV1TNW0/view" target="_blank" rel="noopener noreferrer" class="btn btn-blue"><i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF </a> {% if page.supp %}<a href="" target="_blank" rel="noopener noreferrer" class="btn btn-green"><i class="fa fa-file-text-o" aria-hidden="true"></i> Supplemental </a>{% endif %} {% if page.code %}<a href="https://github.com/sjauhri/Interactive-Learning-in-State-space" target="_blank" rel="noopener noreferrer" class="btn btn-green"><i class="fa fa-github" aria-hidden="true"></i> Code </a>{% endif %} 

#### Authors
**Snehal Jauhri (TU Delft)*; Carlos Celemin (TU Delft); Jens Kober (TU Delft)**

#### Interactive Session
*2020-11-17, 12:30 - 13:00 PST*

#### Abstract
Imitation Learning techniques enable programming the behaviour of agents through demonstrations rather than manual engineering. However, they are limited by the quality of available demonstration data. Interactive Imitation Learning techniques can improve the efficacy of learning since they involve teachers providing feedback while the agent executes its task. In this work, we propose a novel Interactive Learning technique that uses human feedback in state-space to train and improve agent behaviour (as opposed to alternative methods that use feedback in action-space). Our method titled Teaching Imitative Policies in State-space (TIPS) enables providing guidance to the agent in terms of `changing its state' which is often more intuitive for a human demonstrator. Through continuous improvement via corrective feedback, agents trained by non-expert demonstrators using TIPS outperformed the demonstrator and conventional Imitation Learning agents.

#### Video 

#### Reviews

#### Rebuttal

