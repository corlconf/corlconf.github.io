---
layout: page
title: "Interactive Imitation Learning in State-Space"
subtitle: 
description:
permalink: /paper_147/
grand_parent: All Papers
parent: Tuesday
supp: 
code: https://github.com/sjauhri/Interactive-Learning-in-State-space
youtube_id: zG-0cK7qUKY
pdf: https://drive.google.com/file/d/1fRG-p4BaiGSoDw-Y0r6Fn80MXCV1TNW0/view
---

# Interactive Imitation Learning in State-Space

<a href="https://drive.google.com/file/d/1fRG-p4BaiGSoDw-Y0r6Fn80MXCV1TNW0/view" target="_blank" rel="noopener noreferrer" class="btn btn-blue"><i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF </a> {% if page.supp %}<a href="" target="_blank" rel="noopener noreferrer" class="btn btn-green"><i class="fa fa-file-text-o" aria-hidden="true"></i> Supplemental </a>{% endif %} {% if page.code %}<a href="https://github.com/sjauhri/Interactive-Learning-in-State-space" target="_blank" rel="noopener noreferrer" class="btn"><i class="fa fa-github" aria-hidden="true"></i> Code </a>{% endif %} 

#### Authors
**Snehal Jauhri (TU Delft)*; Carlos Celemin (TU Delft); Jens Kober (TU Delft)**

#### Interactive Session
<em>2020-11-17, 12:30 - 13:00 PST </em> | <a href="https://pheedloop.com/corl2020/virtual/?page=sessions&section=SES9SB0W907WVNOKH" target="_blank" rel="noopener noreferrer"> PheedLoop Session <i class="fa fa-external-link" aria-hidden="true"></i> </a> 

#### Abstract
Imitation Learning techniques enable programming the behaviour of agents through demonstrations rather than manual engineering. However, they are limited by the quality of available demonstration data. Interactive Imitation Learning techniques can improve the efficacy of learning since they involve teachers providing feedback while the agent executes its task. In this work, we propose a novel Interactive Learning technique that uses human feedback in state-space to train and improve agent behaviour (as opposed to alternative methods that use feedback in action-space). Our method titled Teaching Imitative Policies in State-space (TIPS) enables providing guidance to the agent in terms of `changing its state' which is often more intuitive for a human demonstrator. Through continuous improvement via corrective feedback, agents trained by non-expert demonstrators using TIPS outperformed the demonstrator and conventional Imitation Learning agents.

#### Video
{% if page.youtube_id %}
{% include youtubePlayer.html id=page.youtube_id %}
{% endif %}

#### Reviews and Rebuttal
<a href="https://drive.google.com/file/d/1jKDb60KWRg7B7GNdT6MVWVbVonWfHuzZ/view" target="_blank" rel="noopener noreferrer" class="btn btn-purple"><i class="fa fa-pencil-square-o" aria-hidden="true"></i> Reviews & Rebuttal </a>

