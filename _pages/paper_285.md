---
layout: page
title: "Learning Trajectories for Visual-Inertial System Calibration via Model-based Heuristic Deep Reinforcement Learning"
subtitle: 
description:
permalink: /paper_285/
grand_parent: All Papers
parent: Monday
supp: 
code: https://github.com/ethz-asl/Learn-to-Calibrate
youtube_id: LZTLDkvwC6U
pdf: https://drive.google.com/file/d/1eDpvtVEdq0ENTKomvlVP7E55LnSU9FQD/view
---

# Learning Trajectories for Visual-Inertial System Calibration via Model-based Heuristic Deep Reinforcement Learning

<a href="https://drive.google.com/file/d/1eDpvtVEdq0ENTKomvlVP7E55LnSU9FQD/view" target="_blank" rel="noopener noreferrer" class="btn btn-blue"><i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF </a> {% if page.supp %}<a href="" target="_blank" rel="noopener noreferrer" class="btn btn-green"><i class="fa fa-file-text-o" aria-hidden="true"></i> Supplemental </a>{% endif %} {% if page.code %}<a href="https://github.com/ethz-asl/Learn-to-Calibrate" target="_blank" rel="noopener noreferrer" class="btn"><i class="fa fa-github" aria-hidden="true"></i> Code </a>{% endif %} 

#### Authors
**Le Chen (ETH Zurich)*; Yunke Ao (ETH Zurich); Florian Tschopp (ETH Zurich); Andrei Cramariuc (ETH Zurich); Michel Breyer (ETH); Jen Jen Chung (ETH Zurich); Roland Siegwart (ETH ZÃ¼rich, Autonomous Systems Lab); Cesar Cadena (ETH Zurich)**

#### Interactive Session
<a href="https://pheedloop.com/corl2020/virtual/?page=sessions&section=SES9KV8I0Q0L4ZTCW" target="_blank" rel="noopener noreferrer"><em>2020-11-16, 12:30 - 13:00 PST </em></a>

#### Abstract
Visual-inertial systems rely on precise calibrations of both camera intrinsics and inter-sensor extrinsics, which typically require manually performing complex motions in front of a calibration target. In this work we present a novel approach to obtain favorable trajectories for visual-inertial system calibration, using model-based deep reinforcement learning. Our key contribution is to model the calibration process as a Markov decision process and then use model-based deep reinforcement learning with particle swarm optimization to establish a sequence of calibration trajectories to be performed by a robot arm. Our experiments show that while maintaining similar or shorter path lengths, the trajectories generated by our learned policy result in lower calibration errors compared to random or handcrafted trajectories. The code is publicly available.

#### Video
{% if page.youtube_id %}
{% include youtubePlayer.html id=page.youtube_id %}
{% endif %}

#### Reviews and Rebuttal
<a href="https://drive.google.com/file/d/1E2c5RcjCanbu9CP41w-efx3qyL1Onz8R/view" target="_blank" rel="noopener noreferrer" class="btn btn-purple"><i class="fa fa-pencil-square-o" aria-hidden="true"></i> Reviews & Rebuttal </a>

