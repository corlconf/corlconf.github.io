---
layout: page
title: "ROLL: Visual Self-Supervised Reinforcement Learning with Object Reasoning"
subtitle: 
description:
permalink: /paper_215/
grand_parent: All Papers
parent: Monday
supp: 
code: https://github.com/yufeiwang63/ROLL
youtubeId: 
---

# ROLL: Visual Self-Supervised Reinforcement Learning with Object Reasoning

[<i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF ](https://drive.google.com/file/d/1Q-0xpq3QU6UlvBFPAEHMkz9ap3xDeiMi/view){: .btn .btn-blue } {% if page.supp %} [<i class="fa fa-file-text-o" aria-hidden="true"></i> Supplementary ]({{ page.supp }}){: .btn .btn-green } {% endif %} {% if page.code %} [<i class="fa fa-github" aria-hidden="true"></i> Code]({{ page.code }}){: .btn .btn-red }
{% endif %}

#### Authors
**Yufei Wang (Carnegie Mellon University)*; Narasimhan Gautham (Carnegie Mellon University); Xingyu Lin (Carnegie Mellon University); Brian Okorn (ROB); David Held (CMU)**

#### Interactive Session
*2020-11-16, 11:50 - 12:20 PST*

#### Abstract
Current image-based reinforcement learning (RL) algorithms typically operate on the whole image without performing object-level reasoning.  This leads to inefficient goal sampling and ineffective reward functions. In this paper, we improve upon previous visual self-supervised RL by incorporating object-level reasoning and occlusion reasoning. Specifically, we use unknown object segmentation to ignore distractors in the scene for better reward computation and goal generation; we further enable occlusion reasoning by employing a novel auxiliary loss and training scheme. We demonstrate that our proposed algorithm, ROLL (Reinforcement learning with Object Level Learning), learns dramatically faster and achieves better final performance compared with previous methods in several simulated visual control tasks. Project video and code
are available at <a href="https://sites.google.com/andrew.cmu.edu/roll" target="_blank">https://sites.google.com/andrew.cmu.edu/roll</a>.

#### Video 

#### Reviews

#### Rebuttal
