---
layout: page
title: "LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar Fusion"
subtitle: 
description:
permalink: /paper_17/
grand_parent: All Papers
parent: Tuesday
supp: 
code: 
youtubeId: 
---

# LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar Fusion

[<i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF ](https://drive.google.com/file/d/1DHcWIcLQpJAozpHQT1XRzkNP2MR3Ilja/view){: .btn .btn-blue } {% if page.supp %} [<i class="fa fa-file-text-o" aria-hidden="true"></i> Supplementary ]({{ page.supp }}){: .btn .btn-green } {% endif %} {% if page.code %} [<i class="fa fa-github" aria-hidden="true"></i> Code]({{ page.code }}){: .btn .btn-red }
{% endif %}

#### Authors
**Meet Shah (Uber ATG)*; Zhiling Huang (Uber ATG); Ankit Laddha (Uber); Matthew Langford (UberATG); Blake Barber (Uber ATG); sida zhang (Uber); Carlos Vallespi-Gonzalez (Uber); Raquel Urtasun (Uber ATG)**

#### Abstract
In this paper, we present LiRaNet, a novel end-to-end trajectory prediction method which utilizes radar sensor information along with widely used lidar and HD maps. Automotive radar provides rich, complementary information, allowing for longer range vehicle detection as well as instantaneous radial velocity measurements. However, there are factors that make the fusion of lidar and radar information challenging, such as the relatively low angular resolution of radar measurements, their sparsity and the lack of exact time synchronization with lidar. To overcome these challenges, we propose an efficient spatio-temporal radar feature extraction scheme which achieves state-of-the-art performance on multiple large-scale datasets. Further, by incorporating radar information, we show a 52% reduction in prediction error for objects with high acceleration and a 16% reduction in prediction error for objects at longer range.

#### Video 

#### Reviews

#### Rebuttal
