---
layout: page
title: "Keypoints into the Future: Self-Supervised Correspondence in Model-Based Reinforcement Learning"
subtitle: 
description:
permalink: /paper_149/
grand_parent: All Papers
parent: Monday
supp: 
code: https://sites.google.com/view/keypointsintothefuture/home
youtube_id: WocKv4ELJ9c
pdf: https://drive.google.com/file/d/1Yvhlpt1QqtCZ1OXulfPmsGbJyKdw48lh/view
---

# Keypoints into the Future: Self-Supervised Correspondence in Model-Based Reinforcement Learning

<a href="https://drive.google.com/file/d/1Yvhlpt1QqtCZ1OXulfPmsGbJyKdw48lh/view" target="_blank" rel="noopener noreferrer" class="btn btn-blue"><i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF </a> {% if page.supp %}<a href="" target="_blank" rel="noopener noreferrer" class="btn btn-green"><i class="fa fa-file-text-o" aria-hidden="true"></i> Supplemental </a>{% endif %} {% if page.code %}<a href="https://sites.google.com/view/keypointsintothefuture/home" target="_blank" rel="noopener noreferrer" class="btn"><i class="fa fa-github" aria-hidden="true"></i> Code </a>{% endif %} 

#### Authors
**Lucas Manuelli (Massachusetts Institute of Technology)*; Yunzhu Li (MIT); Pete Florence (Google); Russ Tedrake (MIT)**

#### Interactive Session
*2020-11-16, 12:30 - 13:00 PST* 

#### Abstract
Predictive models have been at the core of many robotic systems, from quadrotors to walking robots. However, it has been challenging to develop and apply such models to practical robotic manipulation due to high-dimensional sensory observations such as images. Previous approaches to learning models in the context of robotic manipulation have either learned whole image dynamics or used autoencoders to learn dynamics in a low-dimensional latent state. In this work, we introduce model-based prediction with self-supervised visual correspondence learning, and show that not only is this indeed possible, but demonstrate that these types of predictive models show compelling performance improvements over alternative methods for vision-based RL with autoencoder-type vision training. Through simulation experiments, we demonstrate that our models provide better generalization precision, particularly in 3D scenes, scenes involving occlusion, and in category-generalization. Additionally, we validate that our method effectively transfers to the real world through hardware experiments. <a href="https://sites.google.com/view/keypointsintothefuture" target="_blank">https://sites.google.com/view/keypointsintothefuture</a>.

#### Video
{% if page.youtube_id %}
{% include youtubePlayer.html id=page.youtube_id %}
{% endif %}

#### Reviews and Rebuttal
<a href="https://drive.google.com/file/d/1vkgXA-4QLplkJEqt60_XscABWWN2HpGV/view" target="_blank" rel="noopener noreferrer" class="btn btn-purple"><i class="fa fa-pencil-square-o" aria-hidden="true"></i> Reviews & Rebuttal </a>

