---
layout: page
title: "Fast robust peg-in-hole insertion with continuous visual servoing"
subtitle: 
description:
permalink: /paper_384/
grand_parent: All Papers
parent: Wednesday
supp: 
code: 
youtubeId: 
---

# Fast robust peg-in-hole insertion with continuous visual servoing

[<i class="fa fa-file-text-o" aria-hidden="true"></i> Paper PDF ](https://drive.google.com/file/d/1vUtrHNLrQUTDw-DdwH8oLGbpduxrAbai/view){: .btn .btn-blue } {% if page.supp %} [<i class="fa fa-file-text-o" aria-hidden="true"></i> Supplementary ]({{ page.supp }}){: .btn .btn-green } {% endif %} {% if page.code %} [<i class="fa fa-github" aria-hidden="true"></i> Code]({{ page.code }}){: .btn .btn-red }
{% endif %}

#### Authors
**Rasmus Haugaard (University of Southern Denmark)*; Jeppe Langaa (University of Southern Denmark); Christoffer Sloth (University of Southern Denmark); Anders Buch (University of Southern Denmark)**

#### Abstract
This paper demonstrates a visual servoing method which is robust towards uncertainties related to system calibration and grasping, while significantly reducing the peg-in-hole time compared to classical methods and recent attempts based on deep learning. The proposed visual servoing method is based on peg and hole point estimates from a deep neural network in a multi-cam setup, where the model is trained on purely synthetic data. Empirical results show that the learnt model generalizes to the real world, allowing for higher success rates and lower cycle times than existing approaches.

#### Video 

#### Reviews

#### Rebuttal
