{"0": {
    "doc": "All Papers",
    "title": "All Papers",
    "content": ". | ACNMP: Skill Transfer and Task Extrapolation through Learning from Demonstration and Reinforcement Learning via Representation Sharing | Attentional Separation-and-Aggregation Network for Self-supervised Depth-Pose Learning in Dynamic Scenes | Augmenting GAIL with BC for sample efficient imitation learning | BayesRace: Learning to race autonomously using prior experience | CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs | Chaining Behaviors from Data with Model-Free Reinforcement Learning | ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations | Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space | Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching | Deep Reactive Planning in Dynamic Environments | Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control | DeepMPCVS: Deep Model Predictive Control for Visual Servoing | Differentiable Logic Layer for Rule Guided Trajectory Prediction | Diverse Plausible Shape Completions from Ambiguous Depth Images | DROGON: A Trajectory Prediction Model based on Intention-Conditioned Behavior Reasoning | Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning | Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following | From pixels to legs: Hierarchical learning of quadruped locomotion | Harnessing Distribution Ratio Estimators for Learning Agents with Quality and Diversity | Hierarchical Robot Navigation in Novel Environments using Rough 2-D Maps | Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud Forecasting for Sequential Pose Forecasting | Learning a Decentralized Multi-Arm Motion Planner | Learning a Decision Module by Imitating Driver’s Control Behaviors | Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience | Learning Equality Constraints for Motion Planning on Manifolds | Learning from Demonstrations using Signal Temporal Logic | Learning Predictive Models for Ergonomic Control of Prosthetic Devices | Learning to Improve Multi-Robot Hallway Navigation | Learning Vision-based Reactive Policies for Obstacle Avoidance | LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar Fusion | MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control | Model-Based Inverse Reinforcement Learning from Visual Demonstrations | Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation | Multiagent Rollout and Policy Iteration for POMDP with Application to Multi-Robot Repair Problems | Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections | Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design | Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement Learning | Reactive motion planning with probabilisticsafety guarantees | Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation | Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach | S3CNet: A Sparse Semantic Scene Completion Network for LiDAR Point Clouds | Safe Optimal Control Using Stochastic Barrier Functions and Deep Forward-Backward SDEs | Sampling-based Reachability Analysis: A Random Set Theory Approach with Adversarial Sampling | Self-Supervised 3D Keypoint Learning for Ego-Motion Estimation | Self-Supervised Learning of Scene-Graph Representations for Robotic Sequential Manipulation Planning | SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural Networks | Tolerance-Guided Policy Learning for Adaptable and Transferrable Delicate Industrial Insertion | Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control | Transformers for One-Shot Visual Imitation | TriFinger: An Open-Source Robot for Learning Dexterity | Unsupervised Monocular Depth Learning in Dynamic Scenes | Visual Imitation Made Easy | . ",
    "url": "http://localhost:4000/_pages/all.html",
    "relUrl": "/_pages/all.html"
  },"1": {
    "doc": "Home",
    "title": "📄 CoRL Paper Explorer",
    "content": "Welcome to the Corl 2020 Paper Explorer. | Search for a paper above (using any terms in the author, abstract or title). | See all papers that will be presented on a particular day to the left. | . ",
    "url": "http://localhost:4000/#-corl-paper-explorer",
    "relUrl": "/#-corl-paper-explorer"
  },"2": {
    "doc": "Home",
    "title": "Home",
    "content": ". ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"3": {
    "doc": "Monday",
    "title": "Monday",
    "content": " ",
    "url": "http://localhost:4000/_pages/monday.html",
    "relUrl": "/_pages/monday.html"
  },"4": {
    "doc": "Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design",
    "title": "Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design",
    "content": "Paper PDF Supplementary . Authors . Jiankai Sun (CUHK)*; Hao Sun (CUHK); Tian Han (Stevens Institute of Technology); Bolei Zhou (CUHK) . Interactive Session . 2020-11-18, 11:50 - 12:20 PST . Abstract . As a promising topic in cognitive robotics, neuro-symbolic modeling integrates symbolic reasoning and neural representation altogether. However, previous neuro-symbolic models usually wire their structures and the connections manually, making the underlying parameters sub-optimal. In this work, we propose the Neuro-Symbolic Program Search (NSPS) to improve the autonomous driving system design. NSPS is a novel automated search method that synthesizes the Neuro-Symbolic Programs. It can produce robust and expressive Neuro-Symbolic Programs and automatically tune the hyper-parameters. We validate NSPS in the CARLA driving simulation environment. The resulting Neuro-Symbolic Decision Programs successfully handle multiple traffic scenarios. Compared with previous neural-network-based driving and rule-based methods, our neuro-symbolic driving pipeline achieves more stable and safer behaviors in complex driving scenarios while maintaining an interpretable symbolic decision-making process. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_16/",
    "relUrl": "/paper_16/"
  },"5": {
    "doc": "LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar Fusion",
    "title": "LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar Fusion",
    "content": "Paper PDF . Authors . Meet Shah (Uber ATG)*; Zhiling Huang (Uber ATG); Ankit Laddha (Uber); Matthew Langford (UberATG); Blake Barber (Uber ATG); sida zhang (Uber); Carlos Vallespi-Gonzalez (Uber); Raquel Urtasun (Uber ATG) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . In this paper, we present LiRaNet, a novel end-to-end trajectory prediction method which utilizes radar sensor information along with widely used lidar and HD maps. Automotive radar provides rich, complementary information, allowing for longer range vehicle detection as well as instantaneous radial velocity measurements. However, there are factors that make the fusion of lidar and radar information challenging, such as the relatively low angular resolution of radar measurements, their sparsity and the lack of exact time synchronization with lidar. To overcome these challenges, we propose an efficient spatio-temporal radar feature extraction scheme which achieves state-of-the-art performance on multiple large-scale datasets. Further, by incorporating radar information, we show a 52% reduction in prediction error for objects with high acceleration and a 16% reduction in prediction error for objects at longer range. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_17/",
    "relUrl": "/paper_17/"
  },"6": {
    "doc": "DROGON: A Trajectory Prediction Model based on Intention-Conditioned Behavior Reasoning",
    "title": "DROGON: A Trajectory Prediction Model based on Intention-Conditioned Behavior Reasoning",
    "content": "Paper PDF . Authors . Chiho Choi (Honda Research Institute US)*; Srikanth Malla (Honda Research Institute); Abhishek Patil (Hilti Inc); Joon Hee Choi (Sungkyunkwan University) . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . We propose a Deep RObust Goal-Oriented trajectory prediction Network (DROGON) for accurate vehicle trajectory prediction by considering behavioral intentions of vehicles in traffic scenes. Our main insight is that the behavior (i.e., motion) of drivers can be reasoned from their high level possible goals (i.e., intention) on the road. To succeed in such behavior reasoning, we build a conditional prediction model to forecast goal-oriented trajectories with the following stages: (i) relational inference where we encode relational interactions of vehicles using the perceptual context; (ii) intention estimation to compute the probability distributions of intentional goals based on the inferred relations; and (iii) behavior reasoning where we reason about the behaviors of vehicles as trajectories conditioned on the intentions. To this end, we extend the proposed framework to the pedestrian trajectory prediction task, showing the potential applicability toward general trajectory prediction. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_18/",
    "relUrl": "/paper_18/"
  },"7": {
    "doc": "CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs",
    "title": "CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs",
    "content": "Paper PDF Code . Authors . Rohan Chitnis (Massachusetts Institute of Technology)*; Tom Silver (MIT); Beomjoon Kim (MIT); Leslie Kaelbling (MIT); Tomas Lozano-Perez (MIT) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . Meta-planning, or learning to guide planning from experience, is a promising approach to improving the computational cost of planning. A general meta-planning strategy is to learn to impose constraints on the states considered and actions taken by the agent. We observe that (1) imposing a constraint can induce context-specific independences that render some aspects of the domain irrelevant, and (2) an agent can take advantage of this fact by imposing constraints on its own behavior. These observations lead us to propose the context-specific abstract Markov decision process (CAMP), an abstraction of a factored MDP that affords efficient planning. We then describe how to learn constraints to impose so the CAMP optimizes a trade-off between rewards and computational cost. Our experiments consider five planners across four domains, including robotic navigation among movable obstacles (NAMO), robotic task and motion planning for sequential manipulation, and classical planning. We find planning with learned CAMPs to consistently outperform baselines, including Stilman’s NAMO-specific algorithm. Video: https://youtu.be/wTXt6djcAd4 Code: https://git.io/JTnf6 . Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_23/",
    "relUrl": "/paper_23/"
  },"8": {
    "doc": "Augmenting GAIL with BC for sample efficient imitation learning",
    "title": "Augmenting GAIL with BC for sample efficient imitation learning",
    "content": "Paper PDF Code . Authors . Rohit Jena (Carnegie Mellon University)*; Changliu Liu (Carnegie Mellon University); Katia Sycara (Carnegie Mellon University) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . Imitation learning is the problem of recovering an expert policy without access to a reward signal. Behavior cloning and GAIL are two widely used methods for performing imitation learning. Behavior cloning converges in a few iterations, but doesn’t achieve peak performance due to its inherent iid assumption about the state-action distribution. GAIL addresses the issue by accounting for the temporal dependencies when performing a state distribution matching between the agent and the expert. Although GAIL is sample efficient in the number of expert trajectories required, it is still not very sample efficient in terms of the environment interactions needed for convergence of the policy. Given the complementary benefits of both methods, we present a simple and elegant method to combine both methods to enable stable and sample efficient learning. Our algorithm is very simple to implement and integrates with different policy gradient algorithms. We demonstrate the effectiveness of the algorithm in low dimensional control tasks, gridworlds and in high dimensional image-based tasks. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_25/",
    "relUrl": "/paper_25/"
  },"9": {
    "doc": "From pixels to legs: Hierarchical learning of quadruped locomotion",
    "title": "From pixels to legs: Hierarchical learning of quadruped locomotion",
    "content": "Paper PDF . Authors . Deepali Jain (Google)*; Ken Caluwaerts (Google); Atil Iscen (Google) . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . Legged robots navigating crowded scenes and complex terrains in the real world are required to execute dynamic leg movements while processing visual input for obstacle avoidance and path planning. We show that a quadruped robot can acquire both of these skills by means of hierarchical reinforcement learning (HRL). By virtue of their hierarchical structure, our policies learn to implicitly break down this joint problem by concurrently learning High Level (HL) and Low Level (LL) neural network policies. These two levels are connected by a low dimensional hidden layer, which we call latent command. HL receives a first-person camera view, whereas LL receives the latent command from HL and the robot’s on-board sensors to control its actuators. We train policies to walk in two different environments: a curved cliff and a maze. We show that hierarchical policies can concurrently learn to locomote and navigate in these environments, and show they are more efficient than non-hierarchical neural network policies. This architecture also allows for knowledge reuse across tasks. LL networks trained on one task can be transferred to a new task in a new environment. Finally HL, which processes camera images, can be evaluated at much lower and varying frequencies compared to LL, thus reducing computation times and bandwidth requirements. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_28/",
    "relUrl": "/paper_28/"
  },"10": {
    "doc": "Learning a Decentralized Multi-Arm Motion Planner",
    "title": "Learning a Decentralized Multi-Arm Motion Planner",
    "content": "Paper PDF Code . Authors . Huy Ha (Columbia University); Jingxi Xu (Columbia University); Shuran Song (Columbia University)* . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . We present a closed-loop multi-arm motion planner that is scalable and flexible with team size. Traditional multi-arm robotic systems have relied on centralized motion planners, whose run times often scale exponentially with team size, and thus, fail to handle dynamic environments with open-loop control. In this paper, we tackle this problem with multi-agent reinforcement learning, where a shared policy network is trained to control each individual robot arm to reach its target end-effector pose given observations of its workspace state and target end-effector pose. The policy is trained using Soft Actor-Critic with expert demonstrations from a sampling-based motion planning algorithm (i.e., BiRRT). By leveraging classical planning algorithms, we can improve the learning efficiency of the reinforcement learning algorithm while retaining the fast inference time of neural networks. The resulting policy scales sub-linearly and can be deployed on multi-arm systems with variable team sizes. Thanks to the closed-loop and decentralized formulation, our approach generalizes to 5-10 multiarm systems and dynamic moving targets (&gt;90% success rate for a 10-arm system), despite being trained on only 1-4 arm planning tasks with static targets. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_30/",
    "relUrl": "/paper_30/"
  },"11": {
    "doc": "SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural Networks",
    "title": "SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural Networks",
    "content": "Paper PDF . Authors . Yan Xu (The Chinese University of Hong Kong)*; Zhaoyang Huang (Zhejiang University); Kwan-Yee Lin (SenseTime Research); Xinge Zhu (The Chinese University of Hong Kong); Jianping Shi (Sensetime Group Limited); Hujun Bao (Zhejiang University); Guofeng Zhang (Zhejiang University); Hongsheng Li (Chinese University of Hong Kong) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . Recent learning-based LiDAR odometry methods have demonstrated their competitiveness. However, most methods still face two substantial challenges: 1) the 2D projection representation of LiDAR data cannot effectively encode 3D structures from the point clouds; 2) the needs for a large amount of labeled data for training limit the application scope of these methods. In this paper, we propose an self-supervised LiDAR odometry method, dubbed SelfVoxeLO, to tackle these two difficulties. Specifically, we propose a 3D convolution network to process the raw LiDAR data directly, which extracts features that better encode the 3D geometric patterns. To suit our network to self-supervised learning, we design several novel loss functions that utilize the inherent properties of LiDAR point clouds. Moreover, an uncertainty-aware mechanism is incorporated in the loss functions to alleviate the interference of moving objects/noises. We evaluate our method’s performances on two large-scale datasets, i.e., KITTI and Apollo-SouthBay.Our method outperforms state-of-the-art unsupervised methods by 27%/32% in terms of translational/rotational errors on the KITTI dataset and also performs well on the Apollo-SouthBay dataset. By including more unlabelled training data, our method can further improve performance comparable to the supervised methods. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_33/",
    "relUrl": "/paper_33/"
  },"12": {
    "doc": "Learning a Decision Module by Imitating Driver’s Control Behaviors",
    "title": "Learning a Decision Module by Imitating Driver’s Control Behaviors",
    "content": "Paper PDF Supplementary . Authors . Junning Huang (SenseTime Research); Sirui Xie (UCLA); Jiankai Sun (CUHK)*; Qiurui Ma (Hong Kong University of Science and Technology); Chunxiao Liu (SenseTime Research); Dahua Lin (The Chinese University of Hong Kong); Bolei Zhou (CUHK) . Interactive Session . 2020-11-16, 11:50 - 12:20 PST . Abstract . Autonomous driving systems have a pipeline of perception, decision, planning, and control. The decision module processes information from the perception module and directs the execution of downstream planning and control modules. On the other hand, the recent success of deep learning suggests that this pipeline could be replaced by end-to-end neural control policies, however, safety cannot be well guaranteed for the data-driven neural networks. In this work, we propose a hybrid framework to learn neural decisions in the classical modular pipeline through end-to-end imitation learning. This hybrid framework can preserve the merits of the classical pipeline such as the strict enforcement of physical and logical constraints while learning complex driving decisions from data. To circumvent the ambiguous annotation of human driving decisions, our method learns high-level driving decisions by imitating low-level control behaviors. We show in the simulation experiments that our modular driving agent can generalize its driving decision and control to various complex scenarios where the rule-based programs fail. It can also generate smoother and safer driving trajectories than end-to-end neural policies. Demo and code are available at https://decisionforce.github.io/modulardecision/. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_4/",
    "relUrl": "/paper_4/"
  },"13": {
    "doc": "Safe Optimal Control Using Stochastic Barrier Functions and Deep Forward-Backward SDEs",
    "title": "Safe Optimal Control Using Stochastic Barrier Functions and Deep Forward-Backward SDEs",
    "content": "Paper PDF . Authors . Marcus Pereira (Georgia Institute Technology)*; Ziyi Wang (Georgia Institute of Technology); Ioannis Exarchos (Stanford University); Evangelos Theodorou (Georgia Institute of Technology) . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . This paper introduces a new formulation for stochastic optimal control and stochastic dynamic optimization that ensures safety with respect to state and control constraints. The proposed methodology brings together concepts such as Forward-Backward Stochastic Differential Equations, Stochastic Barrier Functions, Differentiable Convex Optimization and Deep Learning. Using the aforementioned concepts, a Neural Network architecture is designed for safe trajectory optimization in which learning can be performed in an end-to-end fashion. Simulations are performed on three systems to show the efficacy of the proposed methodology. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_408/",
    "relUrl": "/paper_408/"
  },"14": {
    "doc": "Diverse Plausible Shape Completions from Ambiguous Depth Images",
    "title": "Diverse Plausible Shape Completions from Ambiguous Depth Images",
    "content": "Paper PDF Code . Authors . Bradley Saund (University of Michigan)*; Dmitry Berenson (University of Michigan) . Interactive Session . 2020-11-16, 11:50 - 12:20 PST . Abstract . We propose PSSNet, a network architecture for generating diverse plausible 3D reconstructions from a single 2.5D depth image. Existing methods tend to produce only small variations on a single shape, even when multiple shapes are consistent with an observation. To obtain diversity we alter a Variational Auto Encoder by providing a learned shape bounding box feature as side information during training. Since these features are known during training, we are able to add a supervised loss to the encoder and noiseless values to the decoder. To evaluate, we sample a set of completions from a network, construct a set of plausible shape matches for each test observation, and compare using our plausible diversity metric defined over sets of shapes. We perform experiments using Shapenet mugs and partially-occluded YCB objects and find that our method performs comparably in datasets with little ambiguity, and outperforms existing methods when many shapes plausibly fit an observed depth image. We demonstrate one use for PSSNet on a physical robot when grasping objects in occlusion and clutter. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_415/",
    "relUrl": "/paper_415/"
  },"15": {
    "doc": "Multiagent Rollout and Policy Iteration for POMDP with Application to Multi-Robot Repair Problems",
    "title": "Multiagent Rollout and Policy Iteration for POMDP with Application to Multi-Robot Repair Problems",
    "content": "Paper PDF . Authors . Sushmita Bhattacharya (Harvard University)*; Siva Kailas (Arizona State University); Sahil Badyal (Arizona State University); Stephanie Gil (Harvard University); Dimitri Bertsekas (Massachusetts Institute of Technology (MIT)) . Interactive Session . 2020-11-16, 11:50 - 12:20 PST . Abstract . In this paper we consider infinite horizon discounted dynamic programming problems with finite state and control spaces, partial state observations, and a multiagent structure. We discuss and compare algorithms that simultaneously or sequentially optimize the agents’ controls by using multistep lookahead, truncated rollout with a known base policy, and a terminal cost function approximation. Our methods specifically address the computational challenges of partially observable multiagent problems. In particular: 1) We consider rollout algorithms that dramatically reduce required computation while preserving the key cost improvement property of the standard rollout method. The per-step computational requirements for our methods are on the order of O(Cm) as compared with O(C^m) for standard rollout, where C is the maximum cardinality of the constraint set for the control component of each agent, and m is the number of agents. 2) We show that our methods can be applied to challenging problems with a graph structure, including a class of robot repair problems whereby multiple robots collaboratively inspect and repair a system under partial information. 3) We provide a simulation study that compares our methods with existing methods, and demonstrate that our methods can handle larger and more complex partially observable multiagent problems (state space size 1E37 and control space size 1E7, respectively). In particular, we verify experimentally that our multiagent rollout methods perform nearly as well as standard rollout for problems with few agents, and produce satisfactory policies for problems with a larger number of agents that are intractable by standard rollout and other state of the art methods. Finally, we incorporate our multiagent rollout algorithms as building blocks in an approximate policy iteration scheme, where successive rollout policies are approximated by using neural network classifiers. While this scheme requires a strictly off-line implementation, it works well in our computational experiments and produces additional significant performance improvement over the single online rollout iteration method. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_416/",
    "relUrl": "/paper_416/"
  },"16": {
    "doc": "Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following",
    "title": "Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following",
    "content": "Paper PDF Code . Authors . Valts Blukis (Cornell University)*; Ross Knepper (Cornell University); Yoav Artzi (Cornell University) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . We study the problem of learning a robot policy to follow natural language instructions that can be easily extended to reason about new objects. We introduce a few-shot language-conditioned object grounding method trained from augmented reality data that uses exemplars to identify objects and align them to their mentions in instructions. We present a learned map representation that encodes object locations and their instructed use, and construct it from our few-shot grounding output. We integrate this mapping approach into an instruction-following policy, thereby allowing it to reason about previously unseen objects at test-time by simply adding exemplars. We evaluate on the task of learning to map raw observations and instructions to continuous control of a physical quadcopter. Our approach significantly outperforms the prior state of the art in the presence of new objects, even when the prior approach observes all objects during training. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_417/",
    "relUrl": "/paper_417/"
  },"17": {
    "doc": "Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space",
    "title": "Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space",
    "content": "Paper PDF Code . Authors . Wilko Schwarting (Massachusetts Institute of Technology)*; Tim Seyde (MIT); Igor Gilitschenski (Massachusetts Institute of Technology); Lucas Liebenwein (Massachusetts Institute of Technology); Ryan Sander (Massachusetts Institute of Technology); Sertac Karaman (Massachusetts Institute of Technology); Daniela Rus (Massachusetts Institute of Technology) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . Learning competitive behaviors in multi-agent settings such as racing requires long-term reasoning about potential adversarial interactions. This paper presents Deep Latent Competition (DLC), a novel reinforcement learning algorithm that learns competitive visual control policies through self-play in imagination. The DLC agent imagines multi-agent interaction sequences in the compact latent space of a learned world model that combines a joint transition function with opponent viewpoint prediction. Imagined self-play reduces costly sample generation in the real world, while the latent representation enables planning to scale gracefully with observation dimensionality. We demonstrate the effectiveness of our algorithm in learning competitive behaviors on a novel multi-agent racing benchmark that requires planning from image observations. Code and videos available at https://sites.google.com/view/deep-latent-competition. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_420/",
    "relUrl": "/paper_420/"
  },"18": {
    "doc": "TriFinger: An Open-Source Robot for Learning Dexterity",
    "title": "TriFinger: An Open-Source Robot for Learning Dexterity",
    "content": "Paper PDF . Authors . Manuel Wuthrich (Max Planck Institute for Intelligent Systems)*; Felix Widmaier (MPI for Intelligent Systems, Tübingen); Felix Grimminger ( Max Planck Institute for Intelligent Systems); Shruti Joshi (IIT Kanpur); Vaibhav Agrawal (Max Planck Institute for Intelligent Systems ); Bilal Hammoud (Max Planck Institute for Intelligent Systems); Majid Khadiv (Max Planck Institute for Intelligent Systems ); Miroslav Bogdanovic (Max Planck Institute for Intelligent Systems); Vincent Berenz (Max Planck Institute for Intelligent Systems); Julian Viereck (NYU); Maximilien Naveau (MPI); Ludovic Righetti (New York University); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen); Stefan Bauer (MPI IS) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . Dexterous object manipulation is still an open problem in robotics, despite the rapid progress in machine learning during the past decade. We argue that a key issue which has hindered progress is the high cost of experimentation on real systems, in terms of both time and money. We address this problem by proposing a novel open-source robotic platform, consisting of hardware and software, to drastically reduce the cost of experimentation. The hardware is inexpensive yet highly dynamic, robust, and capable of complex contact interaction with external objects. The software allows for 1-kilohertz real-time control and performs safety checks to prevent the hardware from breaking. These properties enable the platform to run without human supervision. In addition, we provide easy-to-use C++ and Python interfaces. We illustrate the potential of the proposed platform by performing an object-manipulation task using an optimal-control algorithm and training a learning-based method directly on the real system. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_421/",
    "relUrl": "/paper_421/"
  },"19": {
    "doc": "Learning to Improve Multi-Robot Hallway Navigation",
    "title": "Learning to Improve Multi-Robot Hallway Navigation",
    "content": "Paper PDF . Authors . Jin Soo Park (The University of Texas at Austin)*; Brian Tsang (University of Texas at Austin); Harel Yedidsion (UT Austin); Garrett Warnell (US Army Research Lab); Daehyun Kyoung (The University of Texas at Austin); Peter Stone (University of Texas at Austin and Sony AI) . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . As multi-robot applications become more prevalent, it becomes necessary to develop navigation systems which allow autonomous mobile robots to efficiently and safely pass each other in confined spaces. Existing navigation systems, such as the widely used ROS Navigation Stack, usually produce safe, collision free paths in static environments. However, these systems are not perfect, and when multiple mobile robots simultaneously navigate in narrow spaces, collisions and turnarounds are not uncommon. Fine-tuning and enhancing such navigation stacks is not as simple as it looks since they are made up of multiple layers of code, and there exists a tradeoff between optimizing for efficiency, i.e. minimizing time to destination (TTD) vs. optimizing for safety, i.e. minimizing collisions, with each objective leading to a different combination of parameter values. In this paper we develop a methodology to improve existing navigation stacks with regards to both objectives, without tuning their parameters, while preserving their inherent safety control properties. Our proposed approach is a decentralized learning-based approach that is geared toward real world robotic deployment, by requiring little computing resources. It is agnostic of the underlying navigation stack and can adapt to different types of environmental layouts (i.e., hallway structures). Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_424/",
    "relUrl": "/paper_424/"
  },"20": {
    "doc": "ACNMP: Skill Transfer and Task Extrapolation through Learning from Demonstration and Reinforcement Learning via Representation Sharing",
    "title": "ACNMP: Skill Transfer and Task Extrapolation through Learning from Demonstration and Reinforcement Learning via Representation Sharing",
    "content": "Paper PDF Code . Authors . Mete Akbulut (Bogazici University)*; Erhan Oztop (Ozyeğin Üniversitesi); Muhammet Yunus Seker (Bogazici University); Hh X (University); Ahmet Tekden (Boğaziçi Üniversitesi); Emre Ugur (Bogazici University) . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . To equip robots with dexterous skills, an effective approach is to first transfer the desired skill via Learning from Demonstration (LfD), then let the robot improve it by self-exploration via Reinforcement Learning (RL). In this paper, we propose a novel LfD+RL framework, namely Adaptive Conditional Neural Movement Primitives (ACNMP), that allows efficient policy improvement in novel environments and effective skill transfer between different agents. This is achieved through exploiting the latent representation learned by the underlying Conditional Neural Process (CNP) model, and simultaneous training of the model with supervised learning (SL) for acquiring the demonstrated trajectories and via RL for new trajectory discovery. Through simulation experiments, we show that (i) ACNMP enables the system to extrapolate to situations where pure LfD fails; (ii) Simultaneous training of the system through SL and RL preserves the shape of demonstrations while adapting to novel situations due to the shared representations used by both learners; (iii) ACNMP enables order-of-magnitude sample-efficient RL in extrapolation of reaching tasks compared to the existing approaches; (iv) ACNMPs can be used to implement skill transfer between robots having different morphology, with competitive learning speeds and importantly with less number of assumptions compared to the state-of-the-art approaches. Finally, we show the real-world suitability of ACNMPs through real robot experiments that involve obstacle avoidance, pick and place and pouring actions. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_426/",
    "relUrl": "/paper_426/"
  },"21": {
    "doc": "Unsupervised Monocular Depth Learning in Dynamic Scenes",
    "title": "Unsupervised Monocular Depth Learning in Dynamic Scenes",
    "content": "Paper PDF Supplementary Code . Authors . Hanhan Li (Google AI); Ariel Gordon (Google Research)*; Hang Zhao (Waymo); Vincent Casser (Waymo); Anelia Angelova (Google) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . We present a method for jointly training the estimation of depth, ego-motion, and a dense 3D translation field of objects relative to the scene, with monocular photometric consistency being the sole source of supervision. We show that this apparently heavily underdetermined problem can be regularized by imposing the following prior knowledge about 3D translation fields: they are sparse, since most of the scene is static, and they tend to be piecewise constant for rigid moving objects. We show that this regularization alone is sufficient to train monocular depth prediction models that exceed the accuracy achieved in prior work for dynamic scenes, including methods that require semantic input. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_427/",
    "relUrl": "/paper_427/"
  },"22": {
    "doc": "BayesRace: Learning to race autonomously using prior experience",
    "title": "BayesRace: Learning to race autonomously using prior experience",
    "content": "Paper PDF Code . Authors . Achin Jain (University of Pennsylvania)*; Matthew O’Kelly (University of Pennsylvania); Pratik Chaudhari (University of Pennsylvania); Manfred Morari (University of Pennsylvania) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . Autonomous race cars require perception, estimation, planning, and control modules which work together asynchronously while driving at the limit of a vehicle’s handling capability. A fundamental challenge encountered in designing these software components lies in predicting the vehicle’s future state (e.g. position, orientation, and speed) with high accuracy. The root cause is the difficulty in identifying vehicle model parameters that capture the effects of lateral tire slip. We present a model-based planning and control framework for autonomous racing that significantly reduces the effort required in system identification and control design. Our approach alleviates the gap induced by simulation-based controller design by learning from on-board sensor measurements. A major focus of this work is empirical, thus, we demonstrate our contributions by experiments on validated 1:43 and 1:10 scale autonomous racing simulations. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_428/",
    "relUrl": "/paper_428/"
  },"23": {
    "doc": "Model-Based Inverse Reinforcement Learning from Visual Demonstrations",
    "title": "Model-Based Inverse Reinforcement Learning from Visual Demonstrations",
    "content": "Paper PDF Code . Authors . Neha Das (Facebook AI Research)*; Sarah Bechtle (Max Planck Institute for Intelligent Systems); Todor Davchev (University of Edinburgh); Dinesh Jayaraman (University of Pennsylvania); Akshara Rai (Facebook); Franziska Meier (Facebook AI Research) . Interactive Session . 2020-11-18, 11:50 - 12:20 PST . Abstract . Scaling model-based inverse reinforcement learning (IRL) to real robotic manipulation tasks with unknown dynamics remains an open problem. The key challenges lie in learning good dynamics models, developing algorithms that scale to high-dimensional state-spaces and being able to learn from both visual and proprioceptive demonstrations. In this work, we present a gradient-based inverse reinforcement learning framework that utilizes a pre-trained visual dynamics model to learn cost functions when given only visual human demonstrations. The learned cost functions are then used to reproduce the demonstrated behavior via visual model predictive control. We evaluate our framework on hardware on two basic object manipulation tasks. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_432/",
    "relUrl": "/paper_432/"
  },"24": {
    "doc": "Deep Reactive Planning in Dynamic Environments",
    "title": "Deep Reactive Planning in Dynamic Environments",
    "content": "Paper PDF Code . Authors . Kei Ota (Mitsubishi Electric Corporation)*; Devesh Jha (MERL); Tadashi Onishi (Mitsubishi Electric); Asako Kanezaki (Tokyo Institute of Technology); Yusuke Yoshiyasu (AIST); Yoko Sasaki (National Institute of Advanced Industrial Science and Technology ); Toshisada Mariyama (Mitsubishi Electric); Daniel Nikovski () . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . The main novelty of the proposed approach is that it allows a robot to learn an end-to-end policy which can adapt to changes in the environment during execution. While goal conditioning of policies has been studied in the RL literature, such approaches are not easily extended to settings where the robot’s goal can change during execution. This is something that humans are naturally able to do. However, it is difficult for robots to learn such reflexes (i.e., to naturally respond to dynamic environments), especially when the goal location is not explicitly provided to the robot, and instead needs to be perceived through a vision sensor. In the current work, we present a method that can achieve such behavior by combining traditional kinematic planning, deep learning, and deep reinforcement learning in a synergistic fashion to generalize to arbitrary environments. We demonstrate the proposed approach for several reaching and pick-and-place tasks in simulation, as well as on a real system of a 6-DoF industrial manipulator. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_439/",
    "relUrl": "/paper_439/"
  },"25": {
    "doc": "Reactive motion planning with probabilisticsafety guarantees",
    "title": "Reactive motion planning with probabilisticsafety guarantees",
    "content": "Paper PDF . Authors . Yuxiao Chen (California Institute of Technology)*; Ugo Rosolia (California Institute of Technology); Chuchu Fan (MIT); Aaron Ames (Caltech); Richard Murray (California Institute of Technology) . Interactive Session . 2020-11-16, 11:50 - 12:20 PST . Abstract . Motion planning in environments with multiple agents is critical to many important autonomous applications such as autonomous vehicles and assistive robots. This paper considers the problem of motion planning, where the controlled agent shares the environment with multiple uncontrolled agents. First, a predictive model of the uncontrolled agents is trained to predict all possible trajectories within a short horizon based on the scenario. The prediction is then fed to a motion planning module based on model predictive control. We proved generalization bound for the predictive model using three different methods, post-bloating, support vector machine (SVM), and conformal analysis, all capable of generating stochastic guarantees of the correctness of the predictor. The proposed approach is demonstrated in simulation in a scenario emulating autonomous highway driving. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_440/",
    "relUrl": "/paper_440/"
  },"26": {
    "doc": "Hierarchical Robot Navigation in Novel Environments using Rough 2-D Maps",
    "title": "Hierarchical Robot Navigation in Novel Environments using Rough 2-D Maps",
    "content": "Paper PDF Code . Authors . Chengguang Xu (Northeastern University)*; Christopher Amato (Northeastern University); Lawson Wong (Northeastern University) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST . Abstract . In robot navigation, generalizing quickly to unseen environments is essential. Hierarchical methods inspired by human navigation have been proposed, typically consisting of a high-level landmark proposer and a low-level controller. However, these methods either require precise high-level information to be given in advance, or need to construct such guidance from extensive interaction with the environment. In this work, we propose an approach that leverages a rough 2-D map of the environment to navigate in novel environments without requiring further learning. In particular, we introduce a dynamic topological map that can be initialized from the rough 2-D map along with a high-level planning approach for proposing reachable 2-D map patches of the intermediate landmarks between the start and goal locations. To use proposed 2-D patches, we train a deep generative model to generate intermediate landmarks in observation space which are used as subgoals by low-level goal-conditioned reinforcement learning. Importantly, because the low-level controller is only trained with local behaviors (e.g. go across the intersection, turn left at a corner) on existing environments, this framework allows us to generalize to novel environments given only a rough 2-D map, without requiring further learning. Experimental results demonstrate the effectiveness of the proposed framework in both seen and novel environments. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_442/",
    "relUrl": "/paper_442/"
  },"27": {
    "doc": "Visual Imitation Made Easy",
    "title": "Visual Imitation Made Easy",
    "content": "Paper PDF Supplementary Code . Authors . Sarah Young (UC Berkeley)*; Dhiraj Gandhi (Carnegie Mellon University); Shubham Tulsiani (Facebook AI Research); Abhinav Gupta (CMU/FAIR); Pieter Abbeel (UC Berkeley); Lerrel Pinto (NYU/Berkeley) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . Visual imitation learning provides a framework for learning complex manipulation behaviors by leveraging human demonstrations. However, current interfaces for imitation such as kinesthetic teaching or teleoperation prohibitively restrict our ability to efficiently collect large-scale data in the wild. Obtaining such diverse demonstration data is paramount for the generalization of learned skills to novel scenarios. In this work, we present an alternate interface for imitation that simplifies the data collection process while allowing for easy transfer to robots. We use commercially available reacher-grabber assistive tools both as a data collection device and as the robot’s end-effector. To extract action information from these visual demonstrations, we use off-the-shelf Structure from Motion (SfM) techniques in addition to training a finger detection network. We experimentally evaluate on two challenging tasks: non-prehensile pushing and prehensile stacking, with 1000 diverse demonstrations for each task. For both tasks, we use standard behavior cloning to learn executable policies from the previously collected offline demonstrations. To improve learning performance, we employ a variety of data augmentations and provide an extensive analysis of its effects. Finally, we demonstrate the utility of our interface by evaluating on real robotic scenarios with previously unseen objects and achieve a 87% success rate on pushing and a 62% success rate on stacking. Robot videos are available at our project website: https://sites.google.com/view/visual-imitation-made-easy. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_444/",
    "relUrl": "/paper_444/"
  },"28": {
    "doc": "DeepMPCVS: Deep Model Predictive Control for Visual Servoing",
    "title": "DeepMPCVS: Deep Model Predictive Control for Visual Servoing",
    "content": "Paper PDF Supplementary . Authors . Pushkal Katara (Robotics Research Center, IIITH)*; Harish Y V S (IIIT HYDERABAD); Harit Pandya (University of Lincoln); Abhinav Gupta (International Institute of Information Technology (IIIT), Hyderabad); AadilMehdi Sanchawala (International Institute of Information Technology, Hyderabad); Gourav Kumar (TCS Innovation labs Kolkata); Brojeshwar Bhowmick (Tata Consultancy Services); Madhava Krishna (IIIT-Hyderabad) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . The simplicity of the visual servoing approach makes it an attractive option for tasks dealing with vision-based control of robots in many real-world applications. However, attaining precise alignment for unseen environments pose a challenge to existing visual servoing approaches. While classical approaches assume a perfect world, the recent data-driven approaches face issues when generalizing to novel environments. In this paper, we aim to combine the best of both worlds. We present a deep model predictive visual servoing framework that can achieve precise alignment with optimal trajectories and can generalize to novel environments. Our framework consists of a deep network for optical flow predictions, which are used along with a predictive model to forecast future optical flow. For generating an optimal set of velocities we present a control network that can be trained on-the-fly without any supervision. Through extensive simulations on photo-realistic indoor settings of the popular Habitat framework, we show significant performance gain due to the proposed formulation vis-a-vis recent state of the art methods. Specifically, we show vastly improved performance in trajectory length and faster convergence over recent approaches. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_448/",
    "relUrl": "/paper_448/"
  },"29": {
    "doc": "Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control",
    "title": "Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control",
    "content": "Paper PDF Supplementary Code . Authors . Guangzhi Tang (Rutgers University); Neelesh Kumar (Rutgers University); Raymond Yoo (Rutgers University); Konstantinos Michmizos (Rutgers University)* . Interactive Session . 2020-11-17, 11:50 - 12:20 PST . Abstract . The energy-efficient control of mobile robots has become crucial as the complexity of their real-world applications increasingly involves high-dimensional observation and action spaces, which cannot be offset by their limited on-board resources. An emerging non-Von Neumann model of intelligence, where spiking neural networks (SNNs) are executed on neuromorphic processors, is now considered as an energy-efficient and robust alternative to the state-of-the-art real-time robotic controllers for low dimensional control tasks. The challenge now for this new computing paradigm is to scale so that it can keep up with real-world applications. To do so, SNNs need to overcome the inherent limitations of their training, namely the limited ability of their spiking neurons to represent information and the lack of effective learning algorithms. Here, we propose a population-coded spiking actor network (PopSAN) that was trained in conjunction with a deep critic network using deep reinforcement learning (DRL). The population coding scheme, which is prevalent across brain networks, dramatically increased the representation capacity of the network and the hybrid learning combined the training advantages of deep networks with the energy-efficient inference of spiking networks. To show that our approach can be used for general-purpose spike-based reinforcement learning, we demonstrated its integration with a wide spectrum of policy-gradient based DRL methods covering both on-policy and off-policy DRL algorithms. We deployed the trained PopSAN on Intel’s Loihi neuromorphic chip and benchmarked our method against the mainstream DRL algorithms for continuous control. To allow for a fair comparison among all methods, we validated them on OpenAI gym tasks. Our Loihi-run PopSAN consumed 140 times less energy per inference when compared against the deep actor network on Jetson TX2, and achieved the same level of performance. Our results demonstrate the overall efficiency of neuromorphic controllers and suggest the hybrid reinforcement learning approach as an alternative to deep learning, when both energy-efficiency and robustness are important. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_450/",
    "relUrl": "/paper_450/"
  },"30": {
    "doc": "Tolerance-Guided Policy Learning for Adaptable and Transferrable Delicate Industrial Insertion",
    "title": "Tolerance-Guided Policy Learning for Adaptable and Transferrable Delicate Industrial Insertion",
    "content": "Paper PDF . Authors . Boshen Niu (Carnegie Mellon University); Chenxi Wang (Carnegie Mellon University); Changliu Liu (Carnegie Mellon University)* . Interactive Session . 2020-11-18, 11:50 - 12:20 PST . Abstract . Policy learning for delicate industrial insertion tasks (e.g., PC board assembly) is challenging. This paper considers two major problems: how to learn a diversified policy (instead of just one average policy) that can efficiently handle different workpieces with minimum amount of training data, and how to handle defects of workpieces during insertion. To address the problems, we propose tolerance-guided policy learning. To encourage transferability of the learned policy to different workpieces, we add a task embedding to the policy’s input space using the insertion tolerance. Then we train the policy using generative adversarial imitation learning with reward shaping (RS-GAIL) on a variety of representative situations. To encourage adaptability of the learned policy to handle defects, we build a probabilistic inference model that can output the best inserting pose based on failed insertions using the tolerance model. The best inserting pose is then used as a reference to the learned policy. This proposed method is validated on a sequence of IC socket insertion tasks in simulation. The results show that 1) RS-GAIL can efficiently learn optimal policies under sparse rewards; 2) the tolerance embedding can enhance the transferability of the learned policy; 3) the probabilistic inference makes the policy robust to defects on the workpieces. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_452/",
    "relUrl": "/paper_452/"
  },"31": {
    "doc": "Learning Vision-based Reactive Policies for Obstacle Avoidance",
    "title": "Learning Vision-based Reactive Policies for Obstacle Avoidance",
    "content": "Paper PDF . Authors . Elie Aljalbout (Technical University of Munich)*; Ji Chen (Technical University of Munich); Konstantin Ritt (Technical University of Munich); Maximilian Ulmer (Technical University of Munich); Sami Haddadin (Technical University of Munich) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . In this paper, we address the problem of vision-based obstacle avoidance for robotic manipulators. This topic poses challenges for both perception and motion generation. While most work in the field aims at improving one of those aspects, we provide a unified framework for approaching this problem. The main goal of this framework is to connect perception and motion by identifying the relationship between the visual input and the corresponding motion representation. To this end, we propose a method for learning reactive obstacle avoidance policies. We evaluate our method on goal-reaching tasks for single and multiple obstacles scenarios. We show the ability of the proposed method to efficiently learn stable obstacle avoidance strategies at a high success rate while maintaining closed-loop responsiveness required for critical applications like human-robot interaction. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_454/",
    "relUrl": "/paper_454/"
  },"32": {
    "doc": "Sampling-based Reachability Analysis: A Random Set Theory Approach with Adversarial Sampling",
    "title": "Sampling-based Reachability Analysis: A Random Set Theory Approach with Adversarial Sampling",
    "content": "Paper PDF Code . Authors . Thomas Lew (Stanford University)*; Marco Pavone (Stanford University) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . Reachability analysis is at the core of many applications, from neural network verification, to safe trajectory planning of uncertain systems. However, this problem is notoriously challenging, and current approaches tend to be either too restrictive, too slow, too conservative, or approximate and therefore lack guarantees. In this paper, we propose a simple yet effective sampling-based approach to perform reachability analysis for arbitrary dynamical systems. Our key novel idea consists of using random set theory to give a rigorous interpretation of our method, and prove that it returns sets which are guaranteed to converge to the convex hull of the true reachable sets. Additionally, we leverage recent work on robust deep learning and propose a new adversarial sampling approach to robustify our algorithm and accelerate its convergence. We demonstrate that our method is faster and less conservative than prior work, present results for approximate reachability analysis of neural networks and robust trajectory optimization of high-dimensional uncertain nonlinear systems, and discuss future applications. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_459/",
    "relUrl": "/paper_459/"
  },"33": {
    "doc": "Transformers for One-Shot Visual Imitation",
    "title": "Transformers for One-Shot Visual Imitation",
    "content": "Paper PDF Code . Authors . Sudeep Dasari (Carnegie Mellon University)*; Abhinav Gupta (CMU/FAIR) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST . Abstract . Humans are able to seamlessly visually imitate others, by inferring their intentions and using past experience to achieve the same end goal. In other words, we can parse complex semantic knowledge from raw video and efficiently translate that into concrete motor control. Is it possible to give a robot this same capability? Prior research in robot imitation learning has created agents which can acquire diverse skills from expert human operators. However, expanding these techniques to work with a single positive example during test time is still an open challenge. Apart from control, the difficulty stems from mismatches between the demonstrator and robot domains. For example, objects may be placed in different locations (e.g. kitchen layouts are different in every house). Additionally, the demonstration may come from an agent with different morphology and physical appearance (e.g. human), so one-to-one action correspondences are not available. This paper investigates techniques which allow robots to partially bridge these domain gaps, using their past experience. A neural network is trained to mimic ground truth robot actions given context video from another agent, and must generalize to unseen task instances when prompted with new videos during test time. We hypothesize that our policy representations must be both context driven and dynamics aware in order to perform these tasks. These assumptions are baked into the neural network using the Transformers attention mechanism and a self-supervised inverse dynamics loss. Finally, we experimentally determine that our method accomplishes a 2x improvement in terms of task success rate over prior baselines in a suite of one-shot manipulation tasks. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_463/",
    "relUrl": "/paper_463/"
  },"34": {
    "doc": "Self-Supervised 3D Keypoint Learning for Ego-Motion Estimation",
    "title": "Self-Supervised 3D Keypoint Learning for Ego-Motion Estimation",
    "content": "Paper PDF . Authors . Jiexiong Tang (KTH Royal Institute of Technology)*; Rareș Ambruș (Toyota Research Institute); Vitor Guizilini (Toyota Research Institute); Sudeep Pillai (Toyota Research Institute); Hanme Kim (Toyota Research Institute); Patric Jensfelt (Royal Institute of Technology); Adrien Gaidon (Toyota Research Institute) . Interactive Session . 2020-11-16, 11:50 - 12:20 PST . Abstract . Detecting and matching robust viewpoint-invariant keypoints is critical for visual SLAM and Structure-from-Motion. State-of-the-art learning-based methods generate training samples via homography adaptation to create 2D synthetic views with known keypoint matches from a single image. This approach does not, however, generalize to non-planar 3D scenes with illumination variations commonly seen in real-world videos. In this work, we propose self-supervised learning depth-aware keypoints from unlabeled videos directly. We jointly learn keypoint and depth estimation networks by combining appearance and geometric matching via a differentiable structure-from-motion module based on Procrustean residual pose correction. We show how our self-supervised keypoints can be trivially incorporated into state-of-the-art visual odometry frameworks for robust and accurate ego-motion estimation of autonomous vehicles in real-world conditions. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_464/",
    "relUrl": "/paper_464/"
  },"35": {
    "doc": "Self-Supervised Learning of Scene-Graph Representations for Robotic Sequential Manipulation Planning",
    "title": "Self-Supervised Learning of Scene-Graph Representations for Robotic Sequential Manipulation Planning",
    "content": "Paper PDF Code . Authors . Son Nguyen (University Stuttgart)*; Ozgur Oguz (Uni. of Stuttgart &amp; Max Planck Inst. for Intelligent Systems ); Valentin Hartmann (University of Stuttgart); Marc Toussaint (Technische Universität Berlin) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . We present a self-supervised representation learning approach for visual reasoning and integrate it into a nonlinear program formulation for motion optimization to tackle sequential manipulation tasks. Such problems have usually been addressed by combined task and motion planning approaches, for which spatial relations and logical rules that rely on symbolic representations have to be predefined by the user. We propose to learn relational structures by leveraging visual perception to alleviate the resulting knowledge acquisition bottleneck. In particular, we learn constructing scene-graphs, that represent objects (“red box”), and their spatial relationships (“yellow cylinder on red box”). This representation allows us to plan high-level discrete decisions effectively using graph search algorithms. We integrate the visual reasoning module with a nonlinear optimization method for robot motion planning and verify its feasibility on the classic blocks-world domain. Our proposed framework successfully finds the sequence of actions and enables the robot to execute feasible motion plans to realize the given tasks. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_465/",
    "relUrl": "/paper_465/"
  },"36": {
    "doc": "Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement Learning",
    "title": "Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement Learning",
    "content": "Paper PDF . Authors . Ryan Julian (University of Southern California)*; Benjamin Swanson (Google); Gaurav Sukhatme (University of Southern California); Sergey Levine (Google); Chelsea Finn (Google Brain); Karol Hausman (Google Brain) . Interactive Session . 2020-11-18, 11:50 - 12:20 PST . Abstract . One of the great promises of robot learning systems is that they will be able to learn from their mistakes and continuously adapt to ever-changing environments. Despite this potential, most of the robot learning systems today produce static policies that are not further adapted during deployment, because the algorithms which produce those policies are not designed for continual adaptation. We present an adaptation method, and empirical evidence that it supports a robot learning framework for continual adaption. We show that this very simple method–fine-tuning off-policy reinforcement learning using offline datasets–is robust to changes in background, object shape and appearance, lighting conditions, and robot morphology. We demonstrate how to adapt vision-based robotic manipulation policies to new variations using less than 0.2% of the data necessary to learn the task from scratch. Furthermore, we demonstrate that this robustness holds in an episodic continual learning setting. We also show that pre-training via RL is essential: training from scratch or adapting from super vised ImageNet features are both unsuccessful with such small amounts of data. Our empirical conclusions are consistently supported by experiments on simulated manipulation tasks, and by 60 unique fine-tuning experiments on a real robotic grasping system pre-trained on 580,000 grasps. For video results and an overview of the methods and experiments in this study, see the project website at https://ryanjulian.me/continual-fine-tuning. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_467/",
    "relUrl": "/paper_467/"
  },"37": {
    "doc": "Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning",
    "title": "Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning",
    "content": "Paper PDF Code . Authors . Sean Gillen (UCSB)*; Katie Byl (UCSB) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . A key limitation in using various modern methods of machine learning in developing feedback control policies is the lack of appropriate methodologies to analyze their long-term dynamics, in terms of making any sort of guarantees (even statistically) about robustness. The central reasons for this are largely due to the so-called curse of dimensionality, combined with the black-box nature of the resulting control policies themselves. This paper aims at the first of these issues. Although the full state space of a system may be quite large in dimensionality, it is a common feature of most model-based control methods that the resulting closed-loop systems demonstrate dominant dynamics that are rapidly driven to some lower-dimensional sub-space within. In this work we argue that the dimensionality of this subspace is captured by tools from fractal geometry, namely various notions of a fractional dimension. We then show that the dimensionality of trajectories induced by model free reinforcement learning agents can be influenced adding a post processing function to the agents reward signal. We verify that the dimensionality reduction is robust to noise being added to the system and show that that the modified agents are more actually more robust to noise and push disturbances in general for the systems we examined. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_476/",
    "relUrl": "/paper_476/"
  },"38": {
    "doc": "S3CNet: A Sparse Semantic Scene Completion Network for LiDAR Point Clouds",
    "title": "S3CNet: A Sparse Semantic Scene Completion Network for LiDAR Point Clouds",
    "content": "Paper PDF . Authors . Ran Cheng (Huawei)*; Christopher Agia (University of Toronto); Yuan Ren (Huawei); Xinhai Li (Huawei); Liu Bingbing (Huawei Noah’s Ark Lab, Canada) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . With the increasing reliance of self-driving and similar robotic systems on robust 3D vision, the processing of LiDAR scans with deep convolutional neural networks has become a trend in academia and industry alike. Prior attempts on the challenging Semantic Scene Completion task - which entails the inference of dense 3D structure and associated semantic labels from “sparse” representations - have been, to a degree, successful in small indoor scenes when provided with dense point clouds or dense depth maps often fused with semantic segmentation maps from RGB images. However, the performance of these systems drop drastically when applied to large outdoor scenes characterized by dynamic and exponentially sparser conditions. Likewise, processing of the entire sparse volume becomes infeasible due to memory limitations and workarounds introduce computational inefficiency as practitioners are forced to divide the overall volume into multiple equal segments and infer on each individually, rendering real-time performance impossible. In this work, we formulate a method that subsumes the sparsity of large-scale environments and present S3CNet, a sparse convolution based neural network that predicts the semantically completed scene from a single, unified LiDAR point cloud. We show that our proposed method outperforms all counterparts on the 3D task, achieving state-of-the art results on the SemanticKITTI benchmark. Furthermore, we propose a 2D variant of S3CNet with a multi-view fusion strategy to complement our 3D network, providing robustness to occlusions and extreme sparsity in distant regions. We conduct experiments for the 2D semantic scene completion task and compare the results of our sparse 2D network against several leading LiDAR segmentation models adapted for bird’s eye view segmentation on two open-source datasets. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_478/",
    "relUrl": "/paper_478/"
  },"39": {
    "doc": "Chaining Behaviors from Data with Model-Free Reinforcement Learning",
    "title": "Chaining Behaviors from Data with Model-Free Reinforcement Learning",
    "content": "Paper PDF Code . Authors . Avi Singh (UC Berkeley)*; Albert Yu (UC Berkeley); Jonathan Yang (UC Berkeley); Jesse Zhang (UC Berkeley); Aviral Kumar (UC Berkeley); Sergey Levine (UC Berkeley) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . Reinforcement learning has been applied to a wide variety of robotics problems, but most of such applications involve collecting data from scratch for each new task. Since the amount of robot data we can collect for any single task is limited by time and cost considerations, the learned behavior is typically narrow: the policy can only execute the task in a handful of scenarios that it was trained on. What if there was a way to incorporate a large amount of prior data, either from previously solved tasks or from unsupervised or undirected environment interaction, to extend and generalize learned behaviors? While most prior work on extending robotic skills using pre-collected data focuses on building explicit hierarchies or skill decompositions, we show in this paper that we can reuse prior data to extend new skills simply through model-free reinforcement learning via dynamic programming. We show that even when the prior data does not actually succeed at solving the new task, it can still be utilized for learning a better policy, by providing the agent with a broader understanding of the mechanics of its environment. We demonstrate the effectiveness of such an approach by chaining together several behaviors seen in prior datasets for solving a new task, with our hardest experimental setting involving composing four robotic skills in a row: picking, placing, drawer opening, and grasping, where a +1/0 sparse reward is provided only on task completion. We train our policies in an end-to-end fashion, mapping high-dimensional image observations to low-level robot control commands, and present results in both simulated and real world domains. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_481/",
    "relUrl": "/paper_481/"
  },"40": {
    "doc": "Differentiable Logic Layer for Rule Guided Trajectory Prediction",
    "title": "Differentiable Logic Layer for Rule Guided Trajectory Prediction",
    "content": "Paper PDF . Authors . Xiao Li (MIT)*; Guy Rosman (MIT); Igor Gilitschenski (Massachusetts Institute of Technology); Jonathan DeCastro (Toyota Research Institute); Cristian-Ioan Vasile (Lehigh University); Sertac Karaman (Massachusetts Institute of Technology); Daniela Rus (MIT CSAIL) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . In this work, we propose a method for integration of temporal logic formulas into a neural network. Our main contribution is a new logic optimization layer that uses differentiable optimization on the formulas’ robustness function. This allows incorporating traffic rules into deep learning based trajectory prediction approaches. In the forward pass, an initial prediction from a base predictor is used to initialize and guide the robustness optimization process. Backpropagation through the logic layer allows for simultaneously adjusting the parameters of the rules and the initial prediction network. The integration of a logic layer affords both improved predictions, as well as quantification rule satisfaction and violation during predictor execution. As such, it can serve as a parametric safety- envelope for black box behavior models. We demonstrate how integrating traffic rules improves the predictor performance using real traffic data from the NuScenes dataset. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_482/",
    "relUrl": "/paper_482/"
  },"41": {
    "doc": "Attentional Separation-and-Aggregation Network for Self-supervised Depth-Pose Learning in Dynamic Scenes",
    "title": "Attentional Separation-and-Aggregation Network for Self-supervised Depth-Pose Learning in Dynamic Scenes",
    "content": "Paper PDF . Authors . Feng Gao (Tsinghua University)*; Jincheng Yu (Tsinghua University); Hao Shen (Meituan); Yu Wang (Tsinghua University); Huazhong Yang (Tsinghua University) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . Learning depth and ego-motion from unlabeled videos via self-supervision from epipolar projection can improve the robustness and accuracy of the 3D perception and localization of vision-based robots. However, the rigid projection computed by ego-motion cannot represent all scene points, such as points on moving objects, leading to false guidance in these regions. To address this problem, we propose an Attentional Separation-and-Aggregation Network (ASANet), which can learn to distinguish and extract the scene’s static and dynamic characteristics via the attention mechanism. We further propose a novel MotionNet with an ASANet as the encoder, followed by two separate decoders, to estimate the camera’s ego-motion and the scene’s dynamic motion field. Then, we introduce an auto-selecting approach to detect the moving objects for dynamic-aware learning automatically. Empirical experiments demonstrate that our method can achieve the state-of-the-art performance on the KITTI benchmark. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_487/",
    "relUrl": "/paper_487/"
  },"42": {
    "doc": "Harnessing Distribution Ratio Estimators for Learning Agents with Quality and Diversity",
    "title": "Harnessing Distribution Ratio Estimators for Learning Agents with Quality and Diversity",
    "content": "Paper PDF Supplementary Code . Authors . Tanmay Gangwani (University of Illinois, Urbana Champaign)*; Jian Peng (University of Illinois at Urbana-Champaign); Yuan Zhou (UIUC) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . Quality-Diversity (QD) is a concept from Neuroevolution with some intriguing applications to Reinforcement Learning. It facilitates learning a population of agents where each member is optimized to simultaneously accumulate high task-returns and exhibit behavioral diversity compared to other members. In this paper, we build on a recent kernel-based method for training a QD policy ensemble with Stein variational gradient descent. With kernels based on f-divergence between the stationary distributions of policies, we convert the problem to that of efficient estimation of the ratio of these stationary distributions. We then study various distribution ratio estimators used previously for off-policy evaluation and imitation and re-purpose them to compute the gradients for policies in an ensemble such that the resultant population is diverse and of high-quality. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_496/",
    "relUrl": "/paper_496/"
  },"43": {
    "doc": "Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections",
    "title": "Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections",
    "content": "Paper PDF Code . Authors . Junha Roh (University of Washington); Christoforos Mavrogiannis (University of Washington)*; Rishabh Madan (Indian Institute of Technology Kharagpur); Dieter Fox (NVIDIA Research / University of Washington); Siddhartha Srinivasa (University of Washington) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST . Abstract . We focus on decentralized navigation among multiple non-communicating rational agents at uncontrolled intersections, i.e., street intersections without traffic signs or signals. Avoiding collisions in such domains relies on the ability of agents to predict each others’ intentions reliably, and react quickly. Multiagent trajectory prediction is NP-hard whereas the sample complexity of existing data-driven approaches limits their applicability. Our key insight is that the geometric structure of the intersection and the incentive of agents to move efficiently and avoid collisions (rationality) reduces the space of likely behaviors, effectively relaxing the problem of trajectory prediction. In this paper, we collapse the space of multiagent trajectories at an intersection into a set of modes representing different classes of multiagent behavior, formalized using a notion of topological invariance. Based on this formalism, we design Multiple Topologies Prediction (MTP), a data-driven trajectory-prediction mechanism that reconstructs trajectory representations of high-likelihood modes in multiagent intersection scenes. We show that MTP outperforms a state-of-the-art multimodal trajectory prediction baseline (MFP) in terms of prediction accuracy by 78.24% on a challenging simulated dataset. Finally, we show that MTP enables our optimization-based planner, MTPnav, to achieve collision-free and time-efficient navigation across a variety of challenging intersection scenarios on the CARLA simulator. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_497/",
    "relUrl": "/paper_497/"
  },"44": {
    "doc": "Learning from Demonstrations using Signal Temporal Logic",
    "title": "Learning from Demonstrations using Signal Temporal Logic",
    "content": "Paper PDF . Authors . Aniruddh Puranic (University of Southern California)*; Jyotirmoy Deshmukh (USC); Stefanos Nikolaidis (University of Southern California) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST . Abstract . Learning-from-demonstrations is an emerging paradigm to obtain effective robot control policies for complex tasks via reinforcement learning without the need to explicitly design reward functions. However, it is susceptible to imperfections in demonstrations and also raises concerns of safety and interpretability in the learned control policies. To address these issues, we use Signal Temporal Logic to evaluate and rank the quality of demonstrations. Temporal logic-based specifications allow us to create non-Markovian rewards, and also define interesting causal dependencies between tasks such as sequential task specifications. We validate our approach through experiments on discrete-world and OpenAI Gym environments, and show that our approach outperforms the state-of-the-art Maximum Causal Entropy Inverse Reinforcement Learning. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_498/",
    "relUrl": "/paper_498/"
  },"45": {
    "doc": "MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control",
    "title": "MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control",
    "content": "Paper PDF . Authors . Boris Ivanovic (Stanford University)*; Amine Elhafsi (Stanford University); Guy Rosman (Toyota Research Institute); Adrien Gaidon (Toyota Research Institute); Marco Pavone (Stanford University) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . Reasoning about human motion is a core component of modern human-robot interactive systems. In particular, one of the main uses of behavior prediction in autonomous systems is to inform robot motion planning and control. However, a majority of planning and control algorithms reason about system dynamics rather than the predicted agent tracklets (i.e., ordered sets of waypoints) that are commonly output by trajectory forecasting methods, which can hinder their integration. Towards this end, we propose Mixtures of Affine Time-varying Systems (MATS) as an output representation for trajectory forecasting that is more amenable to downstream planning and control use. Our approach leverages successful ideas from probabilistic trajectory forecasting works to learn dynamical system representations that are well-studied in the planning and control literature. We integrate our predictions with a proposed multimodal planning methodology and demonstrate significant computational efficiency improvements on a large-scale autonomous driving dataset. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_499/",
    "relUrl": "/paper_499/"
  },"46": {
    "doc": "Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach",
    "title": "Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach",
    "content": "Paper PDF Code . Authors . Kartik Paigwar (Indian Institute of Science)*; Lokesh Krishna (IISc); sashank tirumala (IISC Bangalore); naman khetan (IISc); aditya varma (iisc); ashish joglekar (IISc); Shalabh Bhatnagar (Indian Institute of Science (IISc) Bangalore); Ashitava Ghosal (Indian Institute of Science); Bharadwaj Amrutur (IISc Bangalore); Shishir Kolathaya (IISc) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_501/",
    "relUrl": "/paper_501/"
  },"47": {
    "doc": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices",
    "title": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices",
    "content": "Paper PDF Supplementary . Authors . GEOFFEY CLARK (Arizona State University)*; Joseph Campbell (Arizona State University); Heni Ben Amor (Arizona State University) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . We present Model-Predictive Interaction Primitives - a robot learning framework for assistive motion in human-machine collaboration tasks which explicitly accounts for biomechanical impact on the human musculoskeletal system. First, we extend Interaction Primitives to enable predictive biomechanics: the prediction of future biomechanical states of a human partner conditioned on current observations and intended robot control signals. In turn, we leverage this capability within a model-predictive control strategy to identify the future ergonomic and biomechanical ramifications of potential robot actions. Optimal control trajectories are selected so as to minimize future physical impact on the human musculoskeletal system. We empirically demonstrate that our approach minimizes knee or muscle forces via generated control actions selected according to biomechanical cost functions. Experiments are performed in synthetic and real-world experiments involving powered prosthetic devices. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_503/",
    "relUrl": "/paper_503/"
  },"48": {
    "doc": "ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations",
    "title": "ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations",
    "content": "Paper PDF Code . Authors . Samuel Pfrommer (University of Pennsylvania); Mathew Halm (University of Pennsylvania)*; Michael Posa (University of Pennsylvania) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . Common methods for learning robot dynamics assume motion is continuous, causing unrealistic model predictions for systems undergoing discontinuous impact and stiction behavior. In this work, we resolve this conflict with a smooth, implicit encoding of the structure inherent to contact-induced discontinuities. Our method, ContactNets, learns parameterizations of inter-body signed distance and contact-frame Jacobians, a representation that is compatible with many simulation, control, and planning environments for robotics. We furthermore circumvent the need to differentiate through stiff or non-smooth dynamics with a novel loss function inspired by the principles of complementarity and maximum dissipation. Our method can predict realistic impact, non-penetration, and stiction when trained on 60 seconds of real-world data. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_506/",
    "relUrl": "/paper_506/"
  },"49": {
    "doc": "Learning Equality Constraints for Motion Planning on Manifolds",
    "title": "Learning Equality Constraints for Motion Planning on Manifolds",
    "content": "Paper PDF Code . Authors . Giovanni Sutanto (USC); Isabel Rayas Fernández (University of Southern California)*; Peter Englert (University of Southern California); Ragesh Kumar Ramachandran (University of Southern California); Gaurav Sukhatme (University of Southern California) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . Constrained robot motion planning is a widely used technique to solve complex robot tasks. We consider the problem of learning representations of constraints from demonstrations with a deep neural network, which we call Equality Constraint Manifold Neural Network (ECoMaNN). The key idea is to learn a level-set function of the constraint suitable for integration into a constrained sampling-based motion planner. Learning proceeds by aligning subspaces in the network with subspaces of the data. We combine both learned constraints and analytically described constraints into the planner and use a projection-based strategy to find valid points. We evaluate ECoMaNN on its representation capabilities of constraint manifolds, the impact of its individual loss terms, and the motions produced when incorporated into a planner. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_515/",
    "relUrl": "/paper_515/"
  },"50": {
    "doc": "Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation",
    "title": "Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation",
    "content": "Paper PDF . Authors . Florian Voigt (Technical University of Munich)*; Lars Johannsmeier (Technical University of Munich); Sami Haddadin (Technical University of Munich) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST . Abstract . In this paper we apply a multi-level structure to robotic manipulation learning. It consists of a hybrid dynamical system we denote skill and a parameter learning layer that leverages the underlying structure to simplify the problem at hand. For the learning layer we introduce a novel algorithm based on the idea of learning to partition the parameter solution space to quickly and efficiently find good and robust solutions to complex manipulation problems. In a benchmark comparison we show a significant performance increase compared with other black-box optimization algorithms such as HiREPS and particle swarm optimization. Furthermore, we validate and compare our approach on a very hard real-world manipulation problem, namely inserting a key into a lock, with state-of-the-art deep reinforcement learning. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_516/",
    "relUrl": "/paper_516/"
  },"51": {
    "doc": "Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience",
    "title": "Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience",
    "content": "Paper PDF . Authors . Robert Lee (Queensland University of Technology)*; Daniel Ward (The University of Queensland); Vibhavari Dasagi (Queensland University of Technology); Akansel Cosgun (Monash University); Juxi Leitner (QUT); Peter Corke (Queensland University of Technology) . Interactive Session . 2020-11-18, 11:50 - 12:20 PST . Abstract . Manipulating deformable objects, such as fabric, is a long standing problem in robotics, with state estimation and control posing a significant challenge for traditional methods. In this paper, we show that it is possible to learn fabric folding skills in only an hour of self-supervised real robot experience, without human supervision or simulation. Our approach relies on fully convolutional networks and the manipulation of visual inputs to exploit learned features, allowing us to create an expressive goal-conditioned pick and place policy that can be trained efficiently with real world robot data only. Folding skills are learned with only a sparse reward function and thus do not require reward function engineering, merely an image of the goal configuration. We demonstrate our method on a set of towel-folding tasks, and show that our approach is able to discover sequential folding strategies, purely from trial-and-error. We achieve state-of-the-art results without the need for demonstrations or simulation, used in prior approaches. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_518/",
    "relUrl": "/paper_518/"
  },"52": {
    "doc": "Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation",
    "title": "Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation",
    "content": "Paper PDF Supplementary Code . Authors . Bryan Chen (UC Berkeley)*; Alexander Sax (UC Berkeley); Francis Lewis (Stanford); Iro Armeni (Stanford University); Silvio Savarese (Stanford University); Amir Zamir (Swiss Federal Institute of Technology (EPFL)); Jitendra Malik (University of California at Berkeley); Lerrel Pinto (NYU/Berkeley) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST . Abstract . Vision-based robotics often factors the control loop into separate components for perception and control. Conventional perception components usually extract hand-engineered features from the visual input that are then used by the control component in an explicit manner. In contrast, recent advances in deep RL make it possible to learn these features end-to-end during training, but the final result is often brittle, fails unexpectedly under minuscule visual shifts, and comes with a high sample complexity cost. In this work, we study the effects of using mid-level visual representations asynchronously trained for traditional computer vision objectives as a generic and easy-to-decode perceptual state in an end-to-end RL framework. We show that the invariances provided by the mid-level representations aid generalization, improve sample complexity, and lead to a higher final performance. Compared to the alternative approaches for incorporating invariances, such as domain randomization, using asynchronously trained mid-level representations scale better to harder problems and larger domain shifts, and consequently, successfully trains policies for tasks where domain randomization or learning-from-scratch failed. Our experimental findings are reported on manipulation and navigation tasks using real robots as well as simulations. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_526/",
    "relUrl": "/paper_526/"
  },"53": {
    "doc": "Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control",
    "title": "Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control",
    "content": "Paper PDF . Authors . Ji Woong Kim (Johns Hopkins University)*; Peiyao Zhang (Johns Hopkins University); Peter Gehlbach (Johns Hopkins Hospital,); Iulian Iordachita (The Johns Hopkins University); Marin Kobilarov (Johns Hopkins University) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST . Abstract . During retinal microsurgery, precise manipulation of the delicate retinal tissue is required for positive surgical outcome. However, accurate manipulation and navigation of surgical tools remain difficult due to a constrained workspace and the top-down view during the surgery, which limits the surgeon’s ability to estimate depth. To alleviate such difficulty, we propose to automate the tool-navigation task by learning to predict relative goal position on the retinal surface from the current tool-tip position. Given an estimated target on the retina, we generate an optimal trajectory leading to the predicted goal while imposing safety-related physical constraints aimed to minimize tissue damage. As an extended task, we generate goal predictions to various points across the retina to localize eye geometry and further generate safe trajectories within the estimated confines. Through experiments in both simulation and with several eye phantoms, we demonstrate that our framework can permit navigation to various points on the retina within 0.089mm and 0.118mm in xy error which is less than the human’s surgeon mean tremor at the tool-tip of 0.180mm. All safety constraints were fulfilled and the algorithm was robust to previously unseen eyes as well as unseen objects in the scene. Live video demonstration is available here: https://youtu.be/n5j5jCCelXk . Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_528/",
    "relUrl": "/paper_528/"
  },"54": {
    "doc": "Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching",
    "title": "Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching",
    "content": "Paper PDF Code . Authors . Zexi Chen (Zhejiang University); Xuecheng Xu (Zhejiang University); Yue Wang (Zhejiang University)*; Rong Xiong (Zhejiang University) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST . Abstract . The crucial step for localization is to match the current observation to the map. When the two sensor modalities are significantly different, matching becomes challenging. In this paper, we present an end-to-end deep phase correlation network (DPCN) to match heterogeneous sensor measurements. In DPCN, the primary component is a differentiable correlation-based estimator that back-propagates the pose error to learnable feature extractors, which addresses the problem that there are no direct common features for supervision. In addition, it eliminates the exhaustive evaluation in some previous methods, improving efficiency. With the interpretable modeling, the network is light-weighted and promising for better generalization. We evaluate the system on both the simulation data and Aero-Ground Dataset which consists of heterogeneous sensor images and aerial images acquired by satellites or aerial robots. The results show that our method is able to match the heterogeneous sensor measurements, outperforming the comparative traditional phase correlation and other learning-based methods. Code is available at https://github.com/jessychen1016/DPCN. Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_530/",
    "relUrl": "/paper_530/"
  },"55": {
    "doc": "Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud Forecasting for Sequential Pose Forecasting",
    "title": "Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud Forecasting for Sequential Pose Forecasting",
    "content": "Paper PDF Code . Authors . Xinshuo Weng (Carnegie Mellon University)*; Jianren Wang (Carnegie Mellon University); Sergey Levine (UC Berkeley); Kris Kitani (Carnegie Mellon University); Nicholas Rhinehart (UC Berkeley) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST . Abstract . Many autonomous systems forecast aspects of the future in order to aid decision-making. For example, self-driving vehicles and robotic manipulation systems often forecast future object poses by first detecting and tracking objects. However, this detect-then-forecast pipeline is expensive to scale, as pose forecasting algorithms typically require labeled sequences of object poses, which are costly to obtain in 3D space. Can we scale performance without requiring additional labels? We hypothesize yes, and propose inverting the detect-then-forecast pipeline. Instead of detecting, tracking and then forecasting the objects, we propose to first forecast 3D sensor data (e.g., point clouds with 100k points) and then detect/track objects on the predicted point cloud sequences to obtain future poses, i.e., a forecast-then-detect pipeline. This inversion makes it less expensive to scale pose forecasting, as the sensor data forecasting task requires no labels. Part of this work’s focus is on the challenging first step - Sequential Pointcloud Forecasting (SPF), for which we also propose an effective approach, SPFNet. To compare our forecast-then-detect pipeline relative to the detect-then-forecast pipeline, we propose an evaluation procedure and two metrics. Through experiments on a robotic manipulation dataset and two driving datasets, we show that SPFNet is effective for the SPF task, our forecast-then-detect pipeline outperforms the detect-then-forecast approaches to which we compared, and that pose forecasting performance improves with the addition of unlabeled data. Our project website is http://www.xinshuoweng.com/projects/SPF2 . Video . Reviews . Rebuttal . ",
    "url": "http://localhost:4000/paper_6/",
    "relUrl": "/paper_6/"
  },"56": {
    "doc": "Tuesday",
    "title": "Tuesday",
    "content": " ",
    "url": "http://localhost:4000/_pages/tuesday.html",
    "relUrl": "/_pages/tuesday.html"
  },"57": {
    "doc": "Wednesday",
    "title": "Wednesday",
    "content": " ",
    "url": "http://localhost:4000/_pages/wednesday.html",
    "relUrl": "/_pages/wednesday.html"
  }
}
