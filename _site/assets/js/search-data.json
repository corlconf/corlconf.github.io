{"0": {
    "doc": "Award Nominees üèÜ",
    "title": " Best System Paper Award Nominees",
    "content": ". | SMARTS: An Open-Source Scalable Multi-Agent RL Training School for Autonomous Driving by Ming Zhou et al. | DIRL: Domain-Invariant Representation Learning for Sim-to-Real Transfer by Ajay Tanwani | . ",
    "url": "http://localhost:4000/awards#-best-system-paper-award-nominees",
    "relUrl": "/awards#-best-system-paper-award-nominees"
  },"1": {
    "doc": "Award Nominees üèÜ",
    "title": " Best Paper Award Nominees",
    "content": ". | Learning Latent Representations to Influence Multi-Agent Interaction by Annie Xie et al. | Guaranteeing Safety of Learned Perception Modules via Measurement-Robust Control Barrier Functions by Sarah Dean et al. | Learning from Suboptimal Demonstration via Self-Supervised Reward Regression by Letian Chen et al. | Safe Optimal Control Using Stochastic Barrier Functions and Deep Forward-Backward SDEs by Marcus A Pereira et al. | . ",
    "url": "http://localhost:4000/awards#-best-paper-award-nominees",
    "relUrl": "/awards#-best-paper-award-nominees"
  },"2": {
    "doc": "Award Nominees üèÜ",
    "title": " Best Paper Presentation Finalists",
    "content": "To be announced on Wednesday, November 18th. ",
    "url": "http://localhost:4000/awards#-best-paper-presentation-finalists",
    "relUrl": "/awards#-best-paper-presentation-finalists"
  },"3": {
    "doc": "Award Nominees üèÜ",
    "title": "Award Nominees üèÜ",
    "content": " ",
    "url": "http://localhost:4000/awards",
    "relUrl": "/awards"
  },"4": {
    "doc": "All Papers",
    "title": "All Papers",
    "content": ". | ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations | Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching | Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience | Learning Equality Constraints for Motion Planning on Manifolds | Learning from Demonstrations using Signal Temporal Logic | Learning Predictive Models for Ergonomic Control of Prosthetic Devices | MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control | Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation | Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections | Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation | Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach | Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control | . ",
    "url": "http://localhost:4000/all",
    "relUrl": "/all"
  },"5": {
    "doc": "Home",
    "title": "üìÑ CoRL Paper Explorer",
    "content": "Welcome to the Corl 2020 Paper Explorer. | Search for a paper above (using any terms in the author, abstract or title). | See all papers that will be presented on a particular day to the left. | . ",
    "url": "http://localhost:4000/#-corl-paper-explorer",
    "relUrl": "/#-corl-paper-explorer"
  },"6": {
    "doc": "Home",
    "title": "Home",
    "content": ". ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"7": {
    "doc": "Monday",
    "title": "Monday",
    "content": " ",
    "url": "http://localhost:4000/monday",
    "relUrl": "/monday"
  },"8": {
    "doc": "Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections",
    "title": "Multimodal Trajectory Prediction via Topological Invariance for Navigation at Uncontrolled Intersections",
    "content": "Paper PDF Code . Authors . Junha Roh (University of Washington); Christoforos Mavrogiannis (University of Washington)*; Rishabh Madan (Indian Institute of Technology Kharagpur); Dieter Fox (NVIDIA Research / University of Washington); Siddhartha Srinivasa (University of Washington) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST | PheedLoop Session . Abstract . We focus on decentralized navigation among multiple non-communicating rational agents at uncontrolled intersections, i.e., street intersections without traffic signs or signals. Avoiding collisions in such domains relies on the ability of agents to predict each others‚Äô intentions reliably, and react quickly. Multiagent trajectory prediction is NP-hard whereas the sample complexity of existing data-driven approaches limits their applicability. Our key insight is that the geometric structure of the intersection and the incentive of agents to move efficiently and avoid collisions (rationality) reduces the space of likely behaviors, effectively relaxing the problem of trajectory prediction. In this paper, we collapse the space of multiagent trajectories at an intersection into a set of modes representing different classes of multiagent behavior, formalized using a notion of topological invariance. Based on this formalism, we design Multiple Topologies Prediction (MTP), a data-driven trajectory-prediction mechanism that reconstructs trajectory representations of high-likelihood modes in multiagent intersection scenes. We show that MTP outperforms a state-of-the-art multimodal trajectory prediction baseline (MFP) in terms of prediction accuracy by 78.24% on a challenging simulated dataset. Finally, we show that MTP enables our optimization-based planner, MTPnav, to achieve collision-free and time-efficient navigation across a variety of challenging intersection scenarios on the CARLA simulator. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_497/",
    "relUrl": "/paper_497/"
  },"9": {
    "doc": "Learning from Demonstrations using Signal Temporal Logic",
    "title": "Learning from Demonstrations using Signal Temporal Logic",
    "content": "Paper PDF . Authors . Aniruddh Puranic (University of Southern California)*; Jyotirmoy Deshmukh (USC); Stefanos Nikolaidis (University of Southern California) . Interactive Session . 2020-11-18, 12:30 - 13:00 PST | PheedLoop Session . Abstract . Learning-from-demonstrations is an emerging paradigm to obtain effective robot control policies for complex tasks via reinforcement learning without the need to explicitly design reward functions. However, it is susceptible to imperfections in demonstrations and also raises concerns of safety and interpretability in the learned control policies. To address these issues, we use Signal Temporal Logic to evaluate and rank the quality of demonstrations. Temporal logic-based specifications allow us to create non-Markovian rewards, and also define interesting causal dependencies between tasks such as sequential task specifications. We validate our approach through experiments on discrete-world and OpenAI Gym environments, and show that our approach outperforms the state-of-the-art Maximum Causal Entropy Inverse Reinforcement Learning. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_498/",
    "relUrl": "/paper_498/"
  },"10": {
    "doc": "MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control",
    "title": "MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control",
    "content": "Paper PDF . Authors . Boris Ivanovic (Stanford University)*; Amine Elhafsi (Stanford University); Guy Rosman (Toyota Research Institute); Adrien Gaidon (Toyota Research Institute); Marco Pavone (Stanford University) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST | PheedLoop Session . Abstract . Reasoning about human motion is a core component of modern human-robot interactive systems. In particular, one of the main uses of behavior prediction in autonomous systems is to inform robot motion planning and control. However, a majority of planning and control algorithms reason about system dynamics rather than the predicted agent tracklets (i.e., ordered sets of waypoints) that are commonly output by trajectory forecasting methods, which can hinder their integration. Towards this end, we propose Mixtures of Affine Time-varying Systems (MATS) as an output representation for trajectory forecasting that is more amenable to downstream planning and control use. Our approach leverages successful ideas from probabilistic trajectory forecasting works to learn dynamical system representations that are well-studied in the planning and control literature. We integrate our predictions with a proposed multimodal planning methodology and demonstrate significant computational efficiency improvements on a large-scale autonomous driving dataset. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_499/",
    "relUrl": "/paper_499/"
  },"11": {
    "doc": "Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach",
    "title": "Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach",
    "content": "Paper PDF Code . Authors . Kartik Paigwar (Indian Institute of Science)*; Lokesh Krishna (IISc); sashank tirumala (IISC Bangalore); naman khetan (IISc); aditya varma (iisc); ashish joglekar (IISc); Shalabh Bhatnagar (Indian Institute of Science (IISc) Bangalore); Ashitava Ghosal (Indian Institute of Science); Bharadwaj Amrutur (IISc Bangalore); Shishir Kolathaya (IISc) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST | PheedLoop Session . Abstract . In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_501/",
    "relUrl": "/paper_501/"
  },"12": {
    "doc": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices",
    "title": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices",
    "content": "Paper PDF Supplemental . Authors . GEOFFEY CLARK (Arizona State University)*; Joseph Campbell (Arizona State University); Heni Ben Amor (Arizona State University) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST | PheedLoop Session . Abstract . We present Model-Predictive Interaction Primitives - a robot learning framework for assistive motion in human-machine collaboration tasks which explicitly accounts for biomechanical impact on the human musculoskeletal system. First, we extend Interaction Primitives to enable predictive biomechanics: the prediction of future biomechanical states of a human partner conditioned on current observations and intended robot control signals. In turn, we leverage this capability within a model-predictive control strategy to identify the future ergonomic and biomechanical ramifications of potential robot actions. Optimal control trajectories are selected so as to minimize future physical impact on the human musculoskeletal system. We empirically demonstrate that our approach minimizes knee or muscle forces via generated control actions selected according to biomechanical cost functions. Experiments are performed in synthetic and real-world experiments involving powered prosthetic devices. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_503/",
    "relUrl": "/paper_503/"
  },"13": {
    "doc": "ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations",
    "title": "ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations",
    "content": "Paper PDF Code . Authors . Samuel Pfrommer (University of Pennsylvania); Mathew Halm (University of Pennsylvania)*; Michael Posa (University of Pennsylvania) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST | PheedLoop Session . Abstract . Common methods for learning robot dynamics assume motion is continuous, causing unrealistic model predictions for systems undergoing discontinuous impact and stiction behavior. In this work, we resolve this conflict with a smooth, implicit encoding of the structure inherent to contact-induced discontinuities. Our method, ContactNets, learns parameterizations of inter-body signed distance and contact-frame Jacobians, a representation that is compatible with many simulation, control, and planning environments for robotics. We furthermore circumvent the need to differentiate through stiff or non-smooth dynamics with a novel loss function inspired by the principles of complementarity and maximum dissipation. Our method can predict realistic impact, non-penetration, and stiction when trained on 60 seconds of real-world data. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_506/",
    "relUrl": "/paper_506/"
  },"14": {
    "doc": "Learning Equality Constraints for Motion Planning on Manifolds",
    "title": "Learning Equality Constraints for Motion Planning on Manifolds",
    "content": "Paper PDF Code . Authors . Giovanni Sutanto (USC); Isabel Rayas Fern√°ndez (University of Southern California)*; Peter Englert (University of Southern California); Ragesh Kumar Ramachandran (University of Southern California); Gaurav Sukhatme (University of Southern California) . Interactive Session . 2020-11-17, 12:30 - 13:00 PST | PheedLoop Session . Abstract . Constrained robot motion planning is a widely used technique to solve complex robot tasks. We consider the problem of learning representations of constraints from demonstrations with a deep neural network, which we call Equality Constraint Manifold Neural Network (ECoMaNN). The key idea is to learn a level-set function of the constraint suitable for integration into a constrained sampling-based motion planner. Learning proceeds by aligning subspaces in the network with subspaces of the data. We combine both learned constraints and analytically described constraints into the planner and use a projection-based strategy to find valid points. We evaluate ECoMaNN on its representation capabilities of constraint manifolds, the impact of its individual loss terms, and the motions produced when incorporated into a planner. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_515/",
    "relUrl": "/paper_515/"
  },"15": {
    "doc": "Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation",
    "title": "Multi-Level Structure vs. End-to-End-Learning in High-Performance Tactile Robotic Manipulation",
    "content": "Paper PDF . Authors . Florian Voigt (Technical University of Munich)*; Lars Johannsmeier (Technical University of Munich); Sami Haddadin (Technical University of Munich) . Interactive Session . 2020-11-17, 11:10 - 11:40 PST | PheedLoop Session . Abstract . In this paper we apply a multi-level structure to robotic manipulation learning. It consists of a hybrid dynamical system we denote skill and a parameter learning layer that leverages the underlying structure to simplify the problem at hand. For the learning layer we introduce a novel algorithm based on the idea of learning to partition the parameter solution space to quickly and efficiently find good and robust solutions to complex manipulation problems. In a benchmark comparison we show a significant performance increase compared with other black-box optimization algorithms such as HiREPS and particle swarm optimization. Furthermore, we validate and compare our approach on a very hard real-world manipulation problem, namely inserting a key into a lock, with state-of-the-art deep reinforcement learning. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_516/",
    "relUrl": "/paper_516/"
  },"16": {
    "doc": "Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience",
    "title": "Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience",
    "content": "Paper PDF . Authors . Robert Lee (Queensland University of Technology)*; Daniel Ward (The University of Queensland); Vibhavari Dasagi (Queensland University of Technology); Akansel Cosgun (Monash University); Juxi Leitner (QUT); Peter Corke (Queensland University of Technology) . Interactive Session . 2020-11-18, 11:50 - 12:20 PST | PheedLoop Session . Abstract . Manipulating deformable objects, such as fabric, is a long standing problem in robotics, with state estimation and control posing a significant challenge for traditional methods. In this paper, we show that it is possible to learn fabric folding skills in only an hour of self-supervised real robot experience, without human supervision or simulation. Our approach relies on fully convolutional networks and the manipulation of visual inputs to exploit learned features, allowing us to create an expressive goal-conditioned pick and place policy that can be trained efficiently with real world robot data only. Folding skills are learned with only a sparse reward function and thus do not require reward function engineering, merely an image of the goal configuration. We demonstrate our method on a set of towel-folding tasks, and show that our approach is able to discover sequential folding strategies, purely from trial-and-error. We achieve state-of-the-art results without the need for demonstrations or simulation, used in prior approaches. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_518/",
    "relUrl": "/paper_518/"
  },"17": {
    "doc": "Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation",
    "title": "Robust Policies via Mid-Level Visual Representations: An Experimental Study in Manipulation and Navigation",
    "content": "Paper PDF Supplemental Code . Authors . Bryan Chen (UC Berkeley)*; Alexander Sax (UC Berkeley); Francis Lewis (Stanford); Iro Armeni (Stanford University); Silvio Savarese (Stanford University); Amir Zamir (Swiss Federal Institute of Technology (EPFL)); Jitendra Malik (University of California at Berkeley); Lerrel Pinto (NYU/Berkeley) . Interactive Session . 2020-11-16, 11:10 - 11:40 PST | PheedLoop Session . Abstract . Vision-based robotics often factors the control loop into separate components for perception and control. Conventional perception components usually extract hand-engineered features from the visual input that are then used by the control component in an explicit manner. In contrast, recent advances in deep RL make it possible to learn these features end-to-end during training, but the final result is often brittle, fails unexpectedly under minuscule visual shifts, and comes with a high sample complexity cost. In this work, we study the effects of using mid-level visual representations asynchronously trained for traditional computer vision objectives as a generic and easy-to-decode perceptual state in an end-to-end RL framework. We show that the invariances provided by the mid-level representations aid generalization, improve sample complexity, and lead to a higher final performance. Compared to the alternative approaches for incorporating invariances, such as domain randomization, using asynchronously trained mid-level representations scale better to harder problems and larger domain shifts, and consequently, successfully trains policies for tasks where domain randomization or learning-from-scratch failed. Our experimental findings are reported on manipulation and navigation tasks using real robots as well as simulations. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_526/",
    "relUrl": "/paper_526/"
  },"18": {
    "doc": "Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control",
    "title": "Towards Autonomous Eye Surgery by Combining Deep Imitation Learning with Optimal Control",
    "content": "Paper PDF . Authors . Ji Woong Kim (Johns Hopkins University)*; Peiyao Zhang (Johns Hopkins University); Peter Gehlbach (Johns Hopkins Hospital,); Iulian Iordachita (The Johns Hopkins University); Marin Kobilarov (Johns Hopkins University) . Interactive Session . 2020-11-18, 11:10 - 11:40 PST | PheedLoop Session . Abstract . During retinal microsurgery, precise manipulation of the delicate retinal tissue is required for positive surgical outcome. However, accurate manipulation and navigation of surgical tools remain difficult due to a constrained workspace and the top-down view during the surgery, which limits the surgeon‚Äôs ability to estimate depth. To alleviate such difficulty, we propose to automate the tool-navigation task by learning to predict relative goal position on the retinal surface from the current tool-tip position. Given an estimated target on the retina, we generate an optimal trajectory leading to the predicted goal while imposing safety-related physical constraints aimed to minimize tissue damage. As an extended task, we generate goal predictions to various points across the retina to localize eye geometry and further generate safe trajectories within the estimated confines. Through experiments in both simulation and with several eye phantoms, we demonstrate that our framework can permit navigation to various points on the retina within 0.089mm and 0.118mm in xy error which is less than the human‚Äôs surgeon mean tremor at the tool-tip of 0.180mm. All safety constraints were fulfilled and the algorithm was robust to previously unseen eyes as well as unseen objects in the scene. Live video demonstration is available here: https://youtu.be/n5j5jCCelXk . Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_528/",
    "relUrl": "/paper_528/"
  },"19": {
    "doc": "Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching",
    "title": "Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching",
    "content": "Paper PDF Code . Authors . Zexi Chen (Zhejiang University); Xuecheng Xu (Zhejiang University); Yue Wang (Zhejiang University)*; Rong Xiong (Zhejiang University) . Interactive Session . 2020-11-16, 12:30 - 13:00 PST | PheedLoop Session . Abstract . The crucial step for localization is to match the current observation to the map. When the two sensor modalities are significantly different, matching becomes challenging. In this paper, we present an end-to-end deep phase correlation network (DPCN) to match heterogeneous sensor measurements. In DPCN, the primary component is a differentiable correlation-based estimator that back-propagates the pose error to learnable feature extractors, which addresses the problem that there are no direct common features for supervision. In addition, it eliminates the exhaustive evaluation in some previous methods, improving efficiency. With the interpretable modeling, the network is light-weighted and promising for better generalization. We evaluate the system on both the simulation data and Aero-Ground Dataset which consists of heterogeneous sensor images and aerial images acquired by satellites or aerial robots. The results show that our method is able to match the heterogeneous sensor measurements, outperforming the comparative traditional phase correlation and other learning-based methods. Code is available at https://github.com/jessychen1016/DPCN. Video . Reviews and Rebuttal . Reviews &amp; Rebuttal . ",
    "url": "http://localhost:4000/paper_530/",
    "relUrl": "/paper_530/"
  },"20": {
    "doc": "Tuesday",
    "title": "Tuesday",
    "content": " ",
    "url": "http://localhost:4000/tuesday",
    "relUrl": "/tuesday"
  },"21": {
    "doc": "Wednesday",
    "title": "Wednesday",
    "content": " ",
    "url": "http://localhost:4000/wednesday",
    "relUrl": "/wednesday"
  }
}
